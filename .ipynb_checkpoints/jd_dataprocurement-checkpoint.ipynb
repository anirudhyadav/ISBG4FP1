{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "import selenium\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.chrome.service import Service as ChromeService\n",
    "# brew install chromedriver \n",
    "\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "from selenium.webdriver.common.by import By\n",
    "import time\n",
    "import re\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "********************\n",
    "JD's related data procurement\n",
    "********************"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***********************\n",
    "DEVOPS URL Create\n",
    "***********************"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['1', '2', '3', '4', '5', '6', '7', '8', '9', '10', '1', '11', '12', '13', '14', '15', '16', '17', '18', '19', '1', '20', '21', '22', '23', '24', '25', '26', '27', '28', '1', '29', '30', '31', '32', '33', '34', '35', '36', '37', '1', '38', '39', '40', '41', '42', '43', '44', '45', '46']\n"
     ]
    }
   ],
   "source": [
    "\n",
    "driver = webdriver.Chrome()\n",
    "\n",
    "# Open the website\n",
    "url = 'https://www.naukri.com/devops-jobs'  # Replace with the URL of the website you want to scrape\n",
    "driver.get(url)\n",
    "time.sleep(2)\n",
    "page_list = []\n",
    "\n",
    "# Part1\n",
    "result_div = driver.find_element(By.CLASS_NAME, \"styles_pages__v1rAK\")\n",
    "\n",
    "# Find all anchor elements within the div\n",
    "result_elements = result_div.find_elements(By.TAG_NAME, \"a\")\n",
    "\n",
    "# Print the text of each anchor element\n",
    "for element in result_elements:\n",
    "    element =element.text\n",
    "    page_list.append((element))\n",
    "\n",
    "\n",
    "# part2\n",
    "url = 'https://www.naukri.com/devops-jobs-15'  # Replace with the URL of the website you want to scrape\n",
    "driver.get(url)\n",
    "time.sleep(2)\n",
    "result_div = driver.find_element(By.CLASS_NAME, \"styles_pages__v1rAK\")\n",
    "# Find all anchor elements within the div\n",
    "result_elements = result_div.find_elements(By.TAG_NAME, \"a\")\n",
    "# Print the text of each anchor element\n",
    "for element in result_elements:\n",
    "    element =element.text\n",
    "    page_list.append((element))\n",
    "\n",
    "\n",
    "# part3\n",
    "url = 'https://www.naukri.com/devops-jobs-24'  # Replace with the URL of the website you want to scrape\n",
    "driver.get(url)\n",
    "time.sleep(2)\n",
    "result_div = driver.find_element(By.CLASS_NAME, \"styles_pages__v1rAK\")\n",
    "# Find all anchor elements within the div\n",
    "result_elements = result_div.find_elements(By.TAG_NAME, \"a\")\n",
    "# Print the text of each anchor element\n",
    "for element in result_elements:\n",
    "    element =element.text\n",
    "    page_list.append((element))\n",
    "\n",
    "# part4\n",
    "url = 'https://www.naukri.com/devops-jobs-33'  # Replace with the URL of the website you want to scrape\n",
    "driver.get(url)\n",
    "time.sleep(2)\n",
    "result_div = driver.find_element(By.CLASS_NAME, \"styles_pages__v1rAK\")\n",
    "# Find all anchor elements within the div\n",
    "result_elements = result_div.find_elements(By.TAG_NAME, \"a\")\n",
    "# Print the text of each anchor element\n",
    "for element in result_elements:\n",
    "    element =element.text\n",
    "    page_list.append((element))\n",
    "    \n",
    "\n",
    "# part5\n",
    "url = 'https://www.naukri.com/devops-jobs-42'  # Replace with the URL of the website you want to scrape\n",
    "driver.get(url)\n",
    "time.sleep(2)\n",
    "result_div = driver.find_element(By.CLASS_NAME, \"styles_pages__v1rAK\")\n",
    "# Find all anchor elements within the div\n",
    "result_elements = result_div.find_elements(By.TAG_NAME, \"a\")\n",
    "# Print the text of each anchor element\n",
    "for element in result_elements:\n",
    "    element =element.text\n",
    "    page_list.append((element))\n",
    "    \n",
    "print(page_list)\n",
    "\n",
    "driver.quit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 2, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 3, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 4, 40, 41, 42, 43, 44, 45, 46, 5, 6, 7, 8, 9]\n",
      "['https://www.naukri.com/devops-jobs-1?ctcFilter=0to3&ctcFilter=3to6&ctcFilter=6to10&ctcFilter=10to15&ctcFilter=15to25&ctcFilter=25', 'https://www.naukri.com/devops-jobs-10?ctcFilter=0to3&ctcFilter=3to6&ctcFilter=6to10&ctcFilter=10to15&ctcFilter=15to25&ctcFilter=25', 'https://www.naukri.com/devops-jobs-11?ctcFilter=0to3&ctcFilter=3to6&ctcFilter=6to10&ctcFilter=10to15&ctcFilter=15to25&ctcFilter=25', 'https://www.naukri.com/devops-jobs-12?ctcFilter=0to3&ctcFilter=3to6&ctcFilter=6to10&ctcFilter=10to15&ctcFilter=15to25&ctcFilter=25', 'https://www.naukri.com/devops-jobs-13?ctcFilter=0to3&ctcFilter=3to6&ctcFilter=6to10&ctcFilter=10to15&ctcFilter=15to25&ctcFilter=25', 'https://www.naukri.com/devops-jobs-14?ctcFilter=0to3&ctcFilter=3to6&ctcFilter=6to10&ctcFilter=10to15&ctcFilter=15to25&ctcFilter=25', 'https://www.naukri.com/devops-jobs-15?ctcFilter=0to3&ctcFilter=3to6&ctcFilter=6to10&ctcFilter=10to15&ctcFilter=15to25&ctcFilter=25', 'https://www.naukri.com/devops-jobs-16?ctcFilter=0to3&ctcFilter=3to6&ctcFilter=6to10&ctcFilter=10to15&ctcFilter=15to25&ctcFilter=25', 'https://www.naukri.com/devops-jobs-17?ctcFilter=0to3&ctcFilter=3to6&ctcFilter=6to10&ctcFilter=10to15&ctcFilter=15to25&ctcFilter=25', 'https://www.naukri.com/devops-jobs-18?ctcFilter=0to3&ctcFilter=3to6&ctcFilter=6to10&ctcFilter=10to15&ctcFilter=15to25&ctcFilter=25', 'https://www.naukri.com/devops-jobs-19?ctcFilter=0to3&ctcFilter=3to6&ctcFilter=6to10&ctcFilter=10to15&ctcFilter=15to25&ctcFilter=25', 'https://www.naukri.com/devops-jobs-2?ctcFilter=0to3&ctcFilter=3to6&ctcFilter=6to10&ctcFilter=10to15&ctcFilter=15to25&ctcFilter=25', 'https://www.naukri.com/devops-jobs-20?ctcFilter=0to3&ctcFilter=3to6&ctcFilter=6to10&ctcFilter=10to15&ctcFilter=15to25&ctcFilter=25', 'https://www.naukri.com/devops-jobs-21?ctcFilter=0to3&ctcFilter=3to6&ctcFilter=6to10&ctcFilter=10to15&ctcFilter=15to25&ctcFilter=25', 'https://www.naukri.com/devops-jobs-22?ctcFilter=0to3&ctcFilter=3to6&ctcFilter=6to10&ctcFilter=10to15&ctcFilter=15to25&ctcFilter=25', 'https://www.naukri.com/devops-jobs-23?ctcFilter=0to3&ctcFilter=3to6&ctcFilter=6to10&ctcFilter=10to15&ctcFilter=15to25&ctcFilter=25', 'https://www.naukri.com/devops-jobs-24?ctcFilter=0to3&ctcFilter=3to6&ctcFilter=6to10&ctcFilter=10to15&ctcFilter=15to25&ctcFilter=25', 'https://www.naukri.com/devops-jobs-25?ctcFilter=0to3&ctcFilter=3to6&ctcFilter=6to10&ctcFilter=10to15&ctcFilter=15to25&ctcFilter=25', 'https://www.naukri.com/devops-jobs-26?ctcFilter=0to3&ctcFilter=3to6&ctcFilter=6to10&ctcFilter=10to15&ctcFilter=15to25&ctcFilter=25', 'https://www.naukri.com/devops-jobs-27?ctcFilter=0to3&ctcFilter=3to6&ctcFilter=6to10&ctcFilter=10to15&ctcFilter=15to25&ctcFilter=25', 'https://www.naukri.com/devops-jobs-28?ctcFilter=0to3&ctcFilter=3to6&ctcFilter=6to10&ctcFilter=10to15&ctcFilter=15to25&ctcFilter=25', 'https://www.naukri.com/devops-jobs-29?ctcFilter=0to3&ctcFilter=3to6&ctcFilter=6to10&ctcFilter=10to15&ctcFilter=15to25&ctcFilter=25', 'https://www.naukri.com/devops-jobs-3?ctcFilter=0to3&ctcFilter=3to6&ctcFilter=6to10&ctcFilter=10to15&ctcFilter=15to25&ctcFilter=25', 'https://www.naukri.com/devops-jobs-30?ctcFilter=0to3&ctcFilter=3to6&ctcFilter=6to10&ctcFilter=10to15&ctcFilter=15to25&ctcFilter=25', 'https://www.naukri.com/devops-jobs-31?ctcFilter=0to3&ctcFilter=3to6&ctcFilter=6to10&ctcFilter=10to15&ctcFilter=15to25&ctcFilter=25', 'https://www.naukri.com/devops-jobs-32?ctcFilter=0to3&ctcFilter=3to6&ctcFilter=6to10&ctcFilter=10to15&ctcFilter=15to25&ctcFilter=25', 'https://www.naukri.com/devops-jobs-33?ctcFilter=0to3&ctcFilter=3to6&ctcFilter=6to10&ctcFilter=10to15&ctcFilter=15to25&ctcFilter=25', 'https://www.naukri.com/devops-jobs-34?ctcFilter=0to3&ctcFilter=3to6&ctcFilter=6to10&ctcFilter=10to15&ctcFilter=15to25&ctcFilter=25', 'https://www.naukri.com/devops-jobs-35?ctcFilter=0to3&ctcFilter=3to6&ctcFilter=6to10&ctcFilter=10to15&ctcFilter=15to25&ctcFilter=25', 'https://www.naukri.com/devops-jobs-36?ctcFilter=0to3&ctcFilter=3to6&ctcFilter=6to10&ctcFilter=10to15&ctcFilter=15to25&ctcFilter=25', 'https://www.naukri.com/devops-jobs-37?ctcFilter=0to3&ctcFilter=3to6&ctcFilter=6to10&ctcFilter=10to15&ctcFilter=15to25&ctcFilter=25', 'https://www.naukri.com/devops-jobs-38?ctcFilter=0to3&ctcFilter=3to6&ctcFilter=6to10&ctcFilter=10to15&ctcFilter=15to25&ctcFilter=25', 'https://www.naukri.com/devops-jobs-39?ctcFilter=0to3&ctcFilter=3to6&ctcFilter=6to10&ctcFilter=10to15&ctcFilter=15to25&ctcFilter=25', 'https://www.naukri.com/devops-jobs-4?ctcFilter=0to3&ctcFilter=3to6&ctcFilter=6to10&ctcFilter=10to15&ctcFilter=15to25&ctcFilter=25', 'https://www.naukri.com/devops-jobs-40?ctcFilter=0to3&ctcFilter=3to6&ctcFilter=6to10&ctcFilter=10to15&ctcFilter=15to25&ctcFilter=25', 'https://www.naukri.com/devops-jobs-41?ctcFilter=0to3&ctcFilter=3to6&ctcFilter=6to10&ctcFilter=10to15&ctcFilter=15to25&ctcFilter=25', 'https://www.naukri.com/devops-jobs-42?ctcFilter=0to3&ctcFilter=3to6&ctcFilter=6to10&ctcFilter=10to15&ctcFilter=15to25&ctcFilter=25', 'https://www.naukri.com/devops-jobs-43?ctcFilter=0to3&ctcFilter=3to6&ctcFilter=6to10&ctcFilter=10to15&ctcFilter=15to25&ctcFilter=25', 'https://www.naukri.com/devops-jobs-44?ctcFilter=0to3&ctcFilter=3to6&ctcFilter=6to10&ctcFilter=10to15&ctcFilter=15to25&ctcFilter=25', 'https://www.naukri.com/devops-jobs-45?ctcFilter=0to3&ctcFilter=3to6&ctcFilter=6to10&ctcFilter=10to15&ctcFilter=15to25&ctcFilter=25', 'https://www.naukri.com/devops-jobs-46?ctcFilter=0to3&ctcFilter=3to6&ctcFilter=6to10&ctcFilter=10to15&ctcFilter=15to25&ctcFilter=25', 'https://www.naukri.com/devops-jobs-5?ctcFilter=0to3&ctcFilter=3to6&ctcFilter=6to10&ctcFilter=10to15&ctcFilter=15to25&ctcFilter=25', 'https://www.naukri.com/devops-jobs-6?ctcFilter=0to3&ctcFilter=3to6&ctcFilter=6to10&ctcFilter=10to15&ctcFilter=15to25&ctcFilter=25', 'https://www.naukri.com/devops-jobs-7?ctcFilter=0to3&ctcFilter=3to6&ctcFilter=6to10&ctcFilter=10to15&ctcFilter=15to25&ctcFilter=25', 'https://www.naukri.com/devops-jobs-8?ctcFilter=0to3&ctcFilter=3to6&ctcFilter=6to10&ctcFilter=10to15&ctcFilter=15to25&ctcFilter=25', 'https://www.naukri.com/devops-jobs-9?ctcFilter=0to3&ctcFilter=3to6&ctcFilter=6to10&ctcFilter=10to15&ctcFilter=15to25&ctcFilter=25']\n"
     ]
    }
   ],
   "source": [
    "# Making the URL list\n",
    "\n",
    "# Page list\n",
    "page_list = list(set(page_list))\n",
    "page_list = sorted(page_list)\n",
    "page_list = [int(digit) for digit in page_list]\n",
    "print(page_list)\n",
    "\n",
    "\n",
    "# base url\n",
    "url = 'https://www.naukri.com/devops-jobs'  # Replace with the URL of the website you want to scrape\n",
    "page_list\n",
    "# # Wait for the results page to load (you might need to adjust the waiting time)\n",
    "time.sleep(2)\n",
    "# print(page_numbers_int)\n",
    "\n",
    "final_url_list_do = []\n",
    "# Example: Extracting information from the results\n",
    "techstack_list =[]\n",
    "for pageid in page_list:\n",
    "    final_url = url +'-'+ str(pageid)+'?ctcFilter=0to3&ctcFilter=3to6&ctcFilter=6to10&ctcFilter=10to15&ctcFilter=15to25&ctcFilter=25'\n",
    "    final_url_list_do.append(final_url)\n",
    "    \n",
    "print(final_url_list_do)\n",
    "\n",
    "driver.quit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "driver = webdriver.Chrome()\n",
    "\n",
    "\n",
    "# base url\n",
    "final_url_list_do\n",
    "\n",
    "# List to store scraped data\n",
    "scraped_data_do = []\n",
    "\n",
    "# Find all job tuple wrapper elements\n",
    "for url in final_url_list_do:\n",
    "    driver.get(url)\n",
    "    wait = WebDriverWait(driver, 10)\n",
    "    job_tuple_wrappers = wait.until(EC.presence_of_all_elements_located((By.CSS_SELECTOR, 'div.srp-jobtuple-wrapper')))\n",
    "    for job_tuple in job_tuple_wrappers:\n",
    "        # Extracting information from each job tuple\n",
    "        job_title = job_tuple.find_element(By.CSS_SELECTOR, 'a.title').text\n",
    "        # company_name = job_tuple.find_element(By.CSS_SELECTOR, 'span.comp-name').text\n",
    "        # rating = job_tuple.find_element(By.CSS_SELECTOR, 'a.rating > span.main-2').text\n",
    "        experience = job_tuple.find_element(By.CSS_SELECTOR, 'span.exp-wrap span.expwdth').get_attribute('title')\n",
    "        salary = job_tuple.find_element(By.CSS_SELECTOR, 'span.ni-job-tuple-icon-srp-rupee span').get_attribute('title')\n",
    "        location = job_tuple.find_element(By.CSS_SELECTOR, 'span.loc-wrap span').get_attribute('title')\n",
    "        job_description = job_tuple.find_element(By.CSS_SELECTOR, 'span.job-desc').text\n",
    "\n",
    "        # Extracting technology stack\n",
    "        tech_stack_elements = job_tuple.find_elements(By.CSS_SELECTOR, 'ul.tags-gt li.tag-li')\n",
    "        tech_stack = [element.text for element in tech_stack_elements]\n",
    "\n",
    "        # Store the scraped data in a dictionary\n",
    "        job_data = {\n",
    "            'job_title': job_title,\n",
    "            # 'company_name': company_name,\n",
    "            # 'rating': rating,\n",
    "            'experience': experience,\n",
    "            'salary': salary,\n",
    "            'location': location,\n",
    "            'job_description': job_description,\n",
    "            'tech_stack': tech_stack,\n",
    "        }\n",
    "\n",
    "        # Append the dictionary to the list\n",
    "        scraped_data_do.append(job_data)\n",
    "\n",
    "driver.quit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Writing to the csv\n",
    "techstack_list_w = scraped_data_do\n",
    "\n",
    "techstack_list_w = pd.DataFrame(techstack_list_w)\n",
    "techstack_list_w.to_csv('JD-Data_DO.csv',index=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***********************\n",
    "Data Scientist URL Creation\n",
    "***********************"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['1', '2', '3', '4', '5', '6', '7', '8', '9', '10', '1', '11', '12', '13', '14', '15', '16', '17', '18', '19', '1', '20', '21', '22', '23', '24', '25', '26', '27', '28', '1', '33', '34', '35', '36', '37', '38', '39']\n"
     ]
    }
   ],
   "source": [
    "\n",
    "driver = webdriver.Chrome()\n",
    "\n",
    "# Open the website\n",
    "url_DataScientist = 'https://www.naukri.com/data-scientist-jobs'  # Replace with the URL of the website you want to scrape\n",
    "driver.get(url_DataScientist)\n",
    "time.sleep(2)\n",
    "page_list_DataScientist = []\n",
    "\n",
    "# Part1\n",
    "result_div_DataScientist = driver.find_element(By.CLASS_NAME, \"styles_pages__v1rAK\")\n",
    "# Find all anchor elements within the div\n",
    "result_elements_DataScientist = result_div_DataScientist.find_elements(By.TAG_NAME, \"a\")\n",
    "# Print the text of each anchor element\n",
    "for element in result_elements_DataScientist:\n",
    "    element =element.text\n",
    "    page_list_DataScientist.append((element))\n",
    "\n",
    "\n",
    "# part2\n",
    "url_DataScientist = 'https://www.naukri.com/data-scientist-jobs-15'  # Replace with the URL of the website you want to scrape\n",
    "driver.get(url_DataScientist)\n",
    "time.sleep(2)\n",
    "result_div_DataScientist = driver.find_element(By.CLASS_NAME, \"styles_pages__v1rAK\")\n",
    "# Find all anchor elements within the div\n",
    "result_elements_DataScientist = result_div_DataScientist.find_elements(By.TAG_NAME, \"a\")\n",
    "# Print the text of each anchor element\n",
    "for element in result_elements_DataScientist:\n",
    "    element =element.text\n",
    "    page_list_DataScientist.append((element))\n",
    "\n",
    "\n",
    "# part3\n",
    "url_DataScientist = 'https://www.naukri.com/data-scientist-jobs-24'  # Replace with the URL of the website you want to scrape\n",
    "driver.get(url_DataScientist)\n",
    "time.sleep(2)\n",
    "result_div_DataScientist = driver.find_element(By.CLASS_NAME, \"styles_pages__v1rAK\")\n",
    "# Find all anchor elements within the div\n",
    "result_elements_DataScientist = result_div_DataScientist.find_elements(By.TAG_NAME, \"a\")\n",
    "# Print the text of each anchor element\n",
    "for element in result_elements_DataScientist:\n",
    "    element =element.text\n",
    "    page_list_DataScientist.append((element))\n",
    "\n",
    "# part4\n",
    "url_DataScientist = 'https://www.naukri.com/data-scientist-jobs-35'  # Replace with the URL of the website you want to scrape\n",
    "driver.get(url_DataScientist)\n",
    "time.sleep(2)\n",
    "result_div_DataScientist = driver.find_element(By.CLASS_NAME, \"styles_pages__v1rAK\")\n",
    "# Find all anchor elements within the div\n",
    "result_elements_DataScientist = result_div_DataScientist.find_elements(By.TAG_NAME, \"a\")\n",
    "# Print the text of each anchor element\n",
    "for element in result_elements_DataScientist:\n",
    "    element =element.text\n",
    "    page_list_DataScientist.append((element))\n",
    "\n",
    "print(page_list_DataScientist)\n",
    "\n",
    "\n",
    "driver.quit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['1', '10', '11', '12', '13', '14', '15', '16', '17', '18', '19', '2', '20', '21', '22', '23', '24', '25', '26', '27', '28', '3', '33', '34', '35', '36', '37', '38', '39', '4', '5', '6', '7', '8', '9']\n",
      "['https://www.naukri.com/data-scientist-jobs-1?roleTypeFilterGid=169&ctcFilter=0to3&ctcFilter=3to6&ctcFilter=6to10&ctcFilter=10to15&ctcFilter=15to25&ctcFilter=25to50&ctcFilter=50to75&clusters=roleGid%2CsalaryRange', 'https://www.naukri.com/data-scientist-jobs-10?roleTypeFilterGid=169&ctcFilter=0to3&ctcFilter=3to6&ctcFilter=6to10&ctcFilter=10to15&ctcFilter=15to25&ctcFilter=25to50&ctcFilter=50to75&clusters=roleGid%2CsalaryRange', 'https://www.naukri.com/data-scientist-jobs-11?roleTypeFilterGid=169&ctcFilter=0to3&ctcFilter=3to6&ctcFilter=6to10&ctcFilter=10to15&ctcFilter=15to25&ctcFilter=25to50&ctcFilter=50to75&clusters=roleGid%2CsalaryRange', 'https://www.naukri.com/data-scientist-jobs-12?roleTypeFilterGid=169&ctcFilter=0to3&ctcFilter=3to6&ctcFilter=6to10&ctcFilter=10to15&ctcFilter=15to25&ctcFilter=25to50&ctcFilter=50to75&clusters=roleGid%2CsalaryRange', 'https://www.naukri.com/data-scientist-jobs-13?roleTypeFilterGid=169&ctcFilter=0to3&ctcFilter=3to6&ctcFilter=6to10&ctcFilter=10to15&ctcFilter=15to25&ctcFilter=25to50&ctcFilter=50to75&clusters=roleGid%2CsalaryRange', 'https://www.naukri.com/data-scientist-jobs-14?roleTypeFilterGid=169&ctcFilter=0to3&ctcFilter=3to6&ctcFilter=6to10&ctcFilter=10to15&ctcFilter=15to25&ctcFilter=25to50&ctcFilter=50to75&clusters=roleGid%2CsalaryRange', 'https://www.naukri.com/data-scientist-jobs-15?roleTypeFilterGid=169&ctcFilter=0to3&ctcFilter=3to6&ctcFilter=6to10&ctcFilter=10to15&ctcFilter=15to25&ctcFilter=25to50&ctcFilter=50to75&clusters=roleGid%2CsalaryRange', 'https://www.naukri.com/data-scientist-jobs-16?roleTypeFilterGid=169&ctcFilter=0to3&ctcFilter=3to6&ctcFilter=6to10&ctcFilter=10to15&ctcFilter=15to25&ctcFilter=25to50&ctcFilter=50to75&clusters=roleGid%2CsalaryRange', 'https://www.naukri.com/data-scientist-jobs-17?roleTypeFilterGid=169&ctcFilter=0to3&ctcFilter=3to6&ctcFilter=6to10&ctcFilter=10to15&ctcFilter=15to25&ctcFilter=25to50&ctcFilter=50to75&clusters=roleGid%2CsalaryRange', 'https://www.naukri.com/data-scientist-jobs-18?roleTypeFilterGid=169&ctcFilter=0to3&ctcFilter=3to6&ctcFilter=6to10&ctcFilter=10to15&ctcFilter=15to25&ctcFilter=25to50&ctcFilter=50to75&clusters=roleGid%2CsalaryRange', 'https://www.naukri.com/data-scientist-jobs-19?roleTypeFilterGid=169&ctcFilter=0to3&ctcFilter=3to6&ctcFilter=6to10&ctcFilter=10to15&ctcFilter=15to25&ctcFilter=25to50&ctcFilter=50to75&clusters=roleGid%2CsalaryRange', 'https://www.naukri.com/data-scientist-jobs-2?roleTypeFilterGid=169&ctcFilter=0to3&ctcFilter=3to6&ctcFilter=6to10&ctcFilter=10to15&ctcFilter=15to25&ctcFilter=25to50&ctcFilter=50to75&clusters=roleGid%2CsalaryRange', 'https://www.naukri.com/data-scientist-jobs-20?roleTypeFilterGid=169&ctcFilter=0to3&ctcFilter=3to6&ctcFilter=6to10&ctcFilter=10to15&ctcFilter=15to25&ctcFilter=25to50&ctcFilter=50to75&clusters=roleGid%2CsalaryRange', 'https://www.naukri.com/data-scientist-jobs-21?roleTypeFilterGid=169&ctcFilter=0to3&ctcFilter=3to6&ctcFilter=6to10&ctcFilter=10to15&ctcFilter=15to25&ctcFilter=25to50&ctcFilter=50to75&clusters=roleGid%2CsalaryRange', 'https://www.naukri.com/data-scientist-jobs-22?roleTypeFilterGid=169&ctcFilter=0to3&ctcFilter=3to6&ctcFilter=6to10&ctcFilter=10to15&ctcFilter=15to25&ctcFilter=25to50&ctcFilter=50to75&clusters=roleGid%2CsalaryRange', 'https://www.naukri.com/data-scientist-jobs-23?roleTypeFilterGid=169&ctcFilter=0to3&ctcFilter=3to6&ctcFilter=6to10&ctcFilter=10to15&ctcFilter=15to25&ctcFilter=25to50&ctcFilter=50to75&clusters=roleGid%2CsalaryRange', 'https://www.naukri.com/data-scientist-jobs-24?roleTypeFilterGid=169&ctcFilter=0to3&ctcFilter=3to6&ctcFilter=6to10&ctcFilter=10to15&ctcFilter=15to25&ctcFilter=25to50&ctcFilter=50to75&clusters=roleGid%2CsalaryRange', 'https://www.naukri.com/data-scientist-jobs-25?roleTypeFilterGid=169&ctcFilter=0to3&ctcFilter=3to6&ctcFilter=6to10&ctcFilter=10to15&ctcFilter=15to25&ctcFilter=25to50&ctcFilter=50to75&clusters=roleGid%2CsalaryRange', 'https://www.naukri.com/data-scientist-jobs-26?roleTypeFilterGid=169&ctcFilter=0to3&ctcFilter=3to6&ctcFilter=6to10&ctcFilter=10to15&ctcFilter=15to25&ctcFilter=25to50&ctcFilter=50to75&clusters=roleGid%2CsalaryRange', 'https://www.naukri.com/data-scientist-jobs-27?roleTypeFilterGid=169&ctcFilter=0to3&ctcFilter=3to6&ctcFilter=6to10&ctcFilter=10to15&ctcFilter=15to25&ctcFilter=25to50&ctcFilter=50to75&clusters=roleGid%2CsalaryRange', 'https://www.naukri.com/data-scientist-jobs-28?roleTypeFilterGid=169&ctcFilter=0to3&ctcFilter=3to6&ctcFilter=6to10&ctcFilter=10to15&ctcFilter=15to25&ctcFilter=25to50&ctcFilter=50to75&clusters=roleGid%2CsalaryRange', 'https://www.naukri.com/data-scientist-jobs-3?roleTypeFilterGid=169&ctcFilter=0to3&ctcFilter=3to6&ctcFilter=6to10&ctcFilter=10to15&ctcFilter=15to25&ctcFilter=25to50&ctcFilter=50to75&clusters=roleGid%2CsalaryRange', 'https://www.naukri.com/data-scientist-jobs-33?roleTypeFilterGid=169&ctcFilter=0to3&ctcFilter=3to6&ctcFilter=6to10&ctcFilter=10to15&ctcFilter=15to25&ctcFilter=25to50&ctcFilter=50to75&clusters=roleGid%2CsalaryRange', 'https://www.naukri.com/data-scientist-jobs-34?roleTypeFilterGid=169&ctcFilter=0to3&ctcFilter=3to6&ctcFilter=6to10&ctcFilter=10to15&ctcFilter=15to25&ctcFilter=25to50&ctcFilter=50to75&clusters=roleGid%2CsalaryRange', 'https://www.naukri.com/data-scientist-jobs-35?roleTypeFilterGid=169&ctcFilter=0to3&ctcFilter=3to6&ctcFilter=6to10&ctcFilter=10to15&ctcFilter=15to25&ctcFilter=25to50&ctcFilter=50to75&clusters=roleGid%2CsalaryRange', 'https://www.naukri.com/data-scientist-jobs-36?roleTypeFilterGid=169&ctcFilter=0to3&ctcFilter=3to6&ctcFilter=6to10&ctcFilter=10to15&ctcFilter=15to25&ctcFilter=25to50&ctcFilter=50to75&clusters=roleGid%2CsalaryRange', 'https://www.naukri.com/data-scientist-jobs-37?roleTypeFilterGid=169&ctcFilter=0to3&ctcFilter=3to6&ctcFilter=6to10&ctcFilter=10to15&ctcFilter=15to25&ctcFilter=25to50&ctcFilter=50to75&clusters=roleGid%2CsalaryRange', 'https://www.naukri.com/data-scientist-jobs-38?roleTypeFilterGid=169&ctcFilter=0to3&ctcFilter=3to6&ctcFilter=6to10&ctcFilter=10to15&ctcFilter=15to25&ctcFilter=25to50&ctcFilter=50to75&clusters=roleGid%2CsalaryRange', 'https://www.naukri.com/data-scientist-jobs-39?roleTypeFilterGid=169&ctcFilter=0to3&ctcFilter=3to6&ctcFilter=6to10&ctcFilter=10to15&ctcFilter=15to25&ctcFilter=25to50&ctcFilter=50to75&clusters=roleGid%2CsalaryRange', 'https://www.naukri.com/data-scientist-jobs-4?roleTypeFilterGid=169&ctcFilter=0to3&ctcFilter=3to6&ctcFilter=6to10&ctcFilter=10to15&ctcFilter=15to25&ctcFilter=25to50&ctcFilter=50to75&clusters=roleGid%2CsalaryRange', 'https://www.naukri.com/data-scientist-jobs-5?roleTypeFilterGid=169&ctcFilter=0to3&ctcFilter=3to6&ctcFilter=6to10&ctcFilter=10to15&ctcFilter=15to25&ctcFilter=25to50&ctcFilter=50to75&clusters=roleGid%2CsalaryRange', 'https://www.naukri.com/data-scientist-jobs-6?roleTypeFilterGid=169&ctcFilter=0to3&ctcFilter=3to6&ctcFilter=6to10&ctcFilter=10to15&ctcFilter=15to25&ctcFilter=25to50&ctcFilter=50to75&clusters=roleGid%2CsalaryRange', 'https://www.naukri.com/data-scientist-jobs-7?roleTypeFilterGid=169&ctcFilter=0to3&ctcFilter=3to6&ctcFilter=6to10&ctcFilter=10to15&ctcFilter=15to25&ctcFilter=25to50&ctcFilter=50to75&clusters=roleGid%2CsalaryRange', 'https://www.naukri.com/data-scientist-jobs-8?roleTypeFilterGid=169&ctcFilter=0to3&ctcFilter=3to6&ctcFilter=6to10&ctcFilter=10to15&ctcFilter=15to25&ctcFilter=25to50&ctcFilter=50to75&clusters=roleGid%2CsalaryRange', 'https://www.naukri.com/data-scientist-jobs-9?roleTypeFilterGid=169&ctcFilter=0to3&ctcFilter=3to6&ctcFilter=6to10&ctcFilter=10to15&ctcFilter=15to25&ctcFilter=25to50&ctcFilter=50to75&clusters=roleGid%2CsalaryRange']\n"
     ]
    }
   ],
   "source": [
    "# Making the URL list\n",
    "\n",
    "# Page list\n",
    "page_list_DataScientist = list(set(page_list_DataScientist))\n",
    "page_list_DataScientist = sorted(page_list_DataScientist)\n",
    "page_list_DataScientist_int = [int(digit) for digit in page_list_DataScientist]\n",
    "print(page_list_DataScientist)\n",
    "\n",
    "\n",
    "# base url\n",
    "url = 'https://www.naukri.com/data-scientist-jobs'  # Replace with the URL of the website you want to scrape\n",
    "page_list_DataScientist\n",
    "# # Wait for the results page to load (you might need to adjust the waiting time)\n",
    "time.sleep(2)\n",
    "# print(page_numbers_int)\n",
    "\n",
    "final_url_list_DataScientist = []\n",
    "# Example: Extracting information from the results\n",
    "techstack_list =[]\n",
    "for pageid in page_list_DataScientist:\n",
    "    final_url_DataScientist = url +'-'+ str(pageid)+'?roleTypeFilterGid=169&ctcFilter=0to3&ctcFilter=3to6&ctcFilter=6to10&ctcFilter=10to15&ctcFilter=15to25&ctcFilter=25to50&ctcFilter=50to75&clusters=roleGid%2CsalaryRange'\n",
    "    final_url_list_DataScientist.append(final_url_DataScientist)\n",
    "    \n",
    "print(final_url_list_DataScientist)\n",
    "\n",
    "driver.quit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "driver = webdriver.Chrome()\n",
    "\n",
    "\n",
    "# base url\n",
    "final_url_list_DataScientist\n",
    "\n",
    "# List to store scraped data\n",
    "scraped_data_ds = []\n",
    "\n",
    "# Find all job tuple wrapper elements\n",
    "for url in final_url_list_DataScientist:\n",
    "    driver.get(url)\n",
    "    wait = WebDriverWait(driver, 10)\n",
    "    job_tuple_wrappers = wait.until(EC.presence_of_all_elements_located((By.CSS_SELECTOR, 'div.srp-jobtuple-wrapper')))\n",
    "    for job_tuple in job_tuple_wrappers:\n",
    "        # Extracting information from each job tuple\n",
    "        job_title = job_tuple.find_element(By.CSS_SELECTOR, 'a.title').text\n",
    "        # company_name = job_tuple.find_element(By.CSS_SELECTOR, 'span.comp-name').text\n",
    "        # rating = job_tuple.find_element(By.CSS_SELECTOR, 'a.rating > span.main-2').text\n",
    "        experience = job_tuple.find_element(By.CSS_SELECTOR, 'span.exp-wrap span.expwdth').get_attribute('title')\n",
    "        salary = job_tuple.find_element(By.CSS_SELECTOR, 'span.ni-job-tuple-icon-srp-rupee span').get_attribute('title')\n",
    "        location = job_tuple.find_element(By.CSS_SELECTOR, 'span.loc-wrap span').get_attribute('title')\n",
    "        job_description = job_tuple.find_element(By.CSS_SELECTOR, 'span.job-desc').text\n",
    "\n",
    "        # Extracting technology stack\n",
    "        tech_stack_elements = job_tuple.find_elements(By.CSS_SELECTOR, 'ul.tags-gt li.tag-li')\n",
    "        tech_stack = [element.text for element in tech_stack_elements]\n",
    "\n",
    "        # Store the scraped data in a dictionary\n",
    "        job_data = {\n",
    "            'job_title': job_title,\n",
    "            # 'company_name': company_name,\n",
    "            # 'rating': rating,\n",
    "            'experience': experience,\n",
    "            'salary': salary,\n",
    "            'location': location,\n",
    "            'job_description': job_description,\n",
    "            'tech_stack': tech_stack,\n",
    "        }\n",
    "\n",
    "        # Append the dictionary to the list\n",
    "        scraped_data_ds.append(job_data)\n",
    "\n",
    "driver.quit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Writing to the csv\n",
    "techstack_list_w = scraped_data_ds\n",
    "\n",
    "techstack_list_w = pd.DataFrame(techstack_list_w)\n",
    "techstack_list_w.to_csv('JD-Data_DS.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /Users/anirudhyadav/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "#!/usr/bin/env python\n",
    "# coding: utf-8\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "import re\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import PorterStemmer\n",
    "import nltk\n",
    "nltk.download('stopwords')\n",
    "import ast"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  profile                                         tech_stack  \\\n",
      "0      DS  [Team management, Prototype, Database design, ...   \n",
      "1      DS  [Computer science, Training, Web technologies,...   \n",
      "2      DS  [deep learning, Statistical analysis, data sci...   \n",
      "3      DS  [RCA, Software design, Version control, Coding...   \n",
      "4      DS  [Data Science, Python, Machine Learning, Model...   \n",
      "\n",
      "                                 tobeclusteredcolumn  \n",
      "0  DS [Team management, Prototype, Database desig...  \n",
      "1  DS [Computer science, Training, Web technologi...  \n",
      "2  DS [deep learning, Statistical analysis, data ...  \n",
      "3  DS [RCA, Software design, Version control, Cod...  \n",
      "4  DS [Data Science, Python, Machine Learning, Mo...  \n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 4099 entries, 0 to 4098\n",
      "Data columns (total 3 columns):\n",
      " #   Column               Non-Null Count  Dtype \n",
      "---  ------               --------------  ----- \n",
      " 0   profile              4099 non-null   object\n",
      " 1   tech_stack           4099 non-null   object\n",
      " 2   tobeclusteredcolumn  4099 non-null   object\n",
      "dtypes: object(3)\n",
      "memory usage: 96.2+ KB\n"
     ]
    }
   ],
   "source": [
    "\n",
    "clustered_dataset = pd.read_csv('jd_data_for_clustering.csv')\n",
    "print(clustered_dataset.head(5))\n",
    "clustered_dataset.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assuming 'roles_dataset.csv' is your dataset with 'profile' and 'tech_stack' columns\n",
    "# dataset = pd.read_csv('jd_data_for_clustering.csv')\n",
    "\n",
    "def cleanJD(tech_stack):\n",
    "    tech_stack = re.sub('RT|cc', ' ', tech_stack)  # remove RT and cc\n",
    "    tech_stack = re.sub('#\\S+', '', tech_stack)  # remove hashtags\n",
    "    tech_stack = re.sub('@\\S+', '  ', tech_stack)  # remove mentions\n",
    "    tech_stack = re.sub('[%s]' % re.escape(\"\"\"!\"#$%&'()*+,-./:;<=>?@[\\]^_`{|}~\"\"\"), ' ', tech_stack)  # remove punctuations\n",
    "    tech_stack = re.sub(r'[^\\x00-\\x7f]',r' ', tech_stack) \n",
    "    tech_stack = re.sub('\\s+', ' ', tech_stack)  # remove extra whitespace\n",
    "    return tech_stack\n",
    "\n",
    "# Text cleaning function\n",
    "def clean_text(text):\n",
    "\n",
    "    # # Apply custom cleaning logic\n",
    "    # text = cleanJD(text)\n",
    "\n",
    "    # Convert to lowercase\n",
    "    text = text.lower()\n",
    "    \n",
    "    # Remove punctuation and special characters\n",
    "    text = re.sub(r'[^a-z\\s]', '', text)\n",
    "    \n",
    "    # Remove stopwords\n",
    "    stop_words = set(stopwords.words('english'))\n",
    "    text = ' '.join(word for word in text.split() if word not in stop_words)\n",
    "    \n",
    "    # Apply stemming\n",
    "    stemmer = PorterStemmer()\n",
    "    text = ' '.join(stemmer.stem(word) for word in text.split())\n",
    "    \n",
    "    return text\n",
    "\n",
    "# Apply text cleaning to the dataset\n",
    "clustered_dataset['tech_stack_cleaned'] = clustered_dataset['tech_stack'].apply(clean_text)\n",
    "\n",
    "# Function to find the role that best matches the cleaned input list of skills\n",
    "def find_matching_role(input_skills, clustered_dataset):\n",
    "    # Combine the input skills into a single string after cleaning\n",
    "    input_skills_text = \" \".join(clean_text(skill) for skill in input_skills)\n",
    "\n",
    "    # Combine the cleaned tech_stack column in the dataset into a single string for each role\n",
    "    clustered_dataset['tech_stack_combined_cleaned'] = clustered_dataset.groupby('profile')['tech_stack_cleaned'].transform(lambda x: \" \".join(x))\n",
    "\n",
    "    # Create a CountVectorizer to convert the cleaned text into vectors\n",
    "    vectorizer = CountVectorizer().fit_transform([input_skills_text] + list(clustered_dataset['tech_stack_combined_cleaned']))\n",
    "\n",
    "    # Calculate the cosine similarity\n",
    "    cosine_similarities = cosine_similarity(vectorizer[0], vectorizer[1:])[0]\n",
    "\n",
    "    # Find the index of the role with the highest similarity\n",
    "    best_matching_role_index = cosine_similarities.argmax()\n",
    "\n",
    "    # Get the profile (role) corresponding to the best matching index\n",
    "    best_matching_role = clustered_dataset.iloc[best_matching_role_index]['profile']\n",
    "\n",
    "    # Set a threshold for similarity to consider a match\n",
    "    similarity_threshold = 0.3\n",
    "\n",
    "    # Check if the best matching role meets the similarity threshold\n",
    "    if cosine_similarities[best_matching_role_index] >= similarity_threshold:\n",
    "        return best_matching_role\n",
    "    else:\n",
    "        return \"No matching role found\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2345             sql dba profession databas administr sql\n",
      "1262                        devop veracod devop tool tool\n",
      "3651    spring boot hibern core java spring mvc produc...\n",
      "3106    java jenkin angularj css ms sql docker reactj ...\n",
      "580     autom sa infrastructur manag applic develop da...\n",
      "Name: tech_stack_cleaned, dtype: object\n"
     ]
    }
   ],
   "source": [
    "print(clustered_dataset['tech_stack_cleaned'].sample(5) )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Manual Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'list'>\n",
      "The input skills match the role: DO\n",
      "<class 'list'>\n",
      "The input skills match the role:  DO\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Example usage 1\n",
    "# input_skills = ['Machine learning', 'Python', 'NLP', 'Analytical', 'TensorFlow', 'Natural language processing']\n",
    "input_skills = ['Automation', 'Azure Cloud', 'Cicd Pipeline', 'SQL Queries', 'Jenkins', 'GIT', 'Docker', 'Ansible']\n",
    "print((input_skills))\n",
    "matching_role = find_matching_role(input_skills, clustered_dataset)\n",
    "\n",
    "# Display the matching role or a message if no matching role is found\n",
    "print(f\"The input skills match the role: {matching_role}\")\n",
    "\n",
    "\n",
    "# Reading the dataset from the local machine having resumes with skills defined\n",
    "resumedata = pd.read_csv('ResumeValidator-ResumeData.csv')\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example usage 2\n",
    "\n",
    "input_skills_list1 = ['xxx', 'yyy', 'aaa', 'bbb', 'ccc','ddd']\n",
    "matching_role1 = find_matching_role(input_skills_list1, clustered_dataset)\n",
    "\n",
    "# Display the matching role\n",
    "print(f\"The input skills match the role: {matching_role1}\")\n",
    "\n",
    "# Example usage 3\n",
    "\n",
    "input_skills_list2 = ['DevOps', 'VMware', 'Nginx', 'JBoss', 'Configuration management', 'Linux', 'Docker', 'Terraform']\n",
    "matching_role2 = find_matching_role(input_skills_list2, clustered_dataset)\n",
    "\n",
    "# Display the matching role\n",
    "print(f\"The input skills match the role: {matching_role2}\")\n",
    "\n",
    "# Example usage 4\n",
    "\n",
    "input_skills_list4 =  ['Hibernate', 'Front end', 'Agile', 'J2Ee', 'HTML','microservices']\n",
    "matching_role4 = find_matching_role(input_skills_list4, clustered_dataset)\n",
    "\n",
    "# Display the matching role\n",
    "print(f\"The input skills match the role: {matching_role4}\")\n",
    "\n",
    "# Example usage 5\n",
    "\n",
    "input_skills_list5 = ['DevOps', 'VMware', 'Nginx', 'JBoss', 'Configuration management', 'Linux', 'Docker', 'Terraform']\n",
    "matching_role5 = find_matching_role(input_skills_list5, clustered_dataset)\n",
    "\n",
    "# Display the matching role\n",
    "print(f\"The input skills match the role: {matching_role5}\")\n",
    "\n",
    "# Example usage 6\n",
    "\n",
    "input_skills_list6 = ['Ops', 'Mongodb Dba', 'Mongo Ops Manager', 'DBMS', 'MongoDB', 'Database administration', 'MongoDB Database', 'Management']\n",
    "matching_role6 = find_matching_role(input_skills_list6, clustered_dataset)\n",
    "\n",
    "# Display the matching role\n",
    "print(f\"The input skills match the role: {matching_role6}\")\n",
    "\n",
    "# Example usage 7\n",
    "\n",
    "input_skills_list7 = ['Smart scan', 'Query Optimization', 'Root Cause Analysis', 'Exadata', 'ZDLRA', 'ZFS', 'Sql Performance Tuning', 'Performance Tuning']\n",
    "matching_role7 = find_matching_role(input_skills_list7, clustered_dataset)\n",
    "\n",
    "# Display the matching role\n",
    "print(f\"The input skills match the role: {matching_role7}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Automated Input Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       Profile                                         tech_stack\n",
      "0  Ramkumar DO  ['Automation', 'Azure Cloud', 'Cicd Pipeline',...\n"
     ]
    }
   ],
   "source": [
    "# Reading the dataset from the local machine having resumes with skills defined\n",
    "resumedata = pd.read_csv('ResumeValidator-ResumeData.csv')\n",
    "print(resumedata.head(1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The input skills match the role: Ramkumar DO is DO\n",
      "The input skills match the role: Kamal DO is DO\n",
      "The input skills match the role: Anirudh Yadav DS is DS\n",
      "The input skills match the role: Sumit Mujumdar DS is DS\n",
      "The input skills match the role: Prem Java is JAVA\n",
      "The input skills match the role: Gaurav Java is No matching role found\n",
      "The input skills match the role: Anurag Java is JAVA\n",
      "The input skills match the role: Ravindra DB is DB\n",
      "The input skills match the role: Shamsh DB is No matching role found\n",
      "The input skills match the role: Anil DB is DB\n",
      "The input skills match the role: Sharat is No matching role found\n"
     ]
    }
   ],
   "source": [
    "# Example usage for each row in the dataset\n",
    "for index, row in resumedata.iterrows():\n",
    "    profile = row['Profile']\n",
    "    tech_stack = row['tech_stack']\n",
    "    \n",
    "    input_skills_list = ast.literal_eval(tech_stack)  # changing dataype from strin to list\n",
    "    # print((profile))\n",
    "    matching_role = find_matching_role(input_skills_list, clustered_dataset)\n",
    "    \n",
    "    # Display the matching role or a message if no matching role is found\n",
    "    print(f\"The input skills match the role: {profile} is {matching_role}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "isb_core_ml",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

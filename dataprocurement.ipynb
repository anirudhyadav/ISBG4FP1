{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "import selenium\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.chrome.service import Service as ChromeService\n",
    "# brew install chromedriver \n",
    "\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "from selenium.webdriver.common.by import By\n",
    "import time\n",
    "import re\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "********************\n",
    "JD's related data procurement\n",
    "********************"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***********************\n",
    "DEVOPS URL Create\n",
    "***********************"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "driver = webdriver.Chrome()\n",
    "\n",
    "# Open the website\n",
    "url = 'https://www.naukri.com/devops-jobs'  # Replace with the URL of the website you want to scrape\n",
    "driver.get(url)\n",
    "time.sleep(2)\n",
    "page_list = []\n",
    "\n",
    "# Part1\n",
    "result_div = driver.find_element(By.CLASS_NAME, \"styles_pages__v1rAK\")\n",
    "\n",
    "# Find all anchor elements within the div\n",
    "result_elements = result_div.find_elements(By.TAG_NAME, \"a\")\n",
    "\n",
    "# Print the text of each anchor element\n",
    "for element in result_elements:\n",
    "    element =element.text\n",
    "    page_list.append((element))\n",
    "\n",
    "\n",
    "# part2\n",
    "url = 'https://www.naukri.com/devops-jobs-15'  # Replace with the URL of the website you want to scrape\n",
    "driver.get(url)\n",
    "time.sleep(2)\n",
    "result_div = driver.find_element(By.CLASS_NAME, \"styles_pages__v1rAK\")\n",
    "# Find all anchor elements within the div\n",
    "result_elements = result_div.find_elements(By.TAG_NAME, \"a\")\n",
    "# Print the text of each anchor element\n",
    "for element in result_elements:\n",
    "    element =element.text\n",
    "    page_list.append((element))\n",
    "\n",
    "\n",
    "# part3\n",
    "url = 'https://www.naukri.com/devops-jobs-24'  # Replace with the URL of the website you want to scrape\n",
    "driver.get(url)\n",
    "time.sleep(2)\n",
    "result_div = driver.find_element(By.CLASS_NAME, \"styles_pages__v1rAK\")\n",
    "# Find all anchor elements within the div\n",
    "result_elements = result_div.find_elements(By.TAG_NAME, \"a\")\n",
    "# Print the text of each anchor element\n",
    "for element in result_elements:\n",
    "    element =element.text\n",
    "    page_list.append((element))\n",
    "\n",
    "# part4\n",
    "url = 'https://www.naukri.com/devops-jobs-33'  # Replace with the URL of the website you want to scrape\n",
    "driver.get(url)\n",
    "time.sleep(2)\n",
    "result_div = driver.find_element(By.CLASS_NAME, \"styles_pages__v1rAK\")\n",
    "# Find all anchor elements within the div\n",
    "result_elements = result_div.find_elements(By.TAG_NAME, \"a\")\n",
    "# Print the text of each anchor element\n",
    "for element in result_elements:\n",
    "    element =element.text\n",
    "    page_list.append((element))\n",
    "    \n",
    "\n",
    "# part5\n",
    "url = 'https://www.naukri.com/devops-jobs-42'  # Replace with the URL of the website you want to scrape\n",
    "driver.get(url)\n",
    "time.sleep(2)\n",
    "result_div = driver.find_element(By.CLASS_NAME, \"styles_pages__v1rAK\")\n",
    "# Find all anchor elements within the div\n",
    "result_elements = result_div.find_elements(By.TAG_NAME, \"a\")\n",
    "# Print the text of each anchor element\n",
    "for element in result_elements:\n",
    "    element =element.text\n",
    "    page_list.append((element))\n",
    "    \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "driver.quit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 2, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 3, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 4, 40, 41, 42, 43, 44, 45, 46, 5, 6, 7, 8, 9]\n",
      "['https://www.naukri.com/devops-jobs-1', 'https://www.naukri.com/devops-jobs-10', 'https://www.naukri.com/devops-jobs-11', 'https://www.naukri.com/devops-jobs-12', 'https://www.naukri.com/devops-jobs-13', 'https://www.naukri.com/devops-jobs-14', 'https://www.naukri.com/devops-jobs-15', 'https://www.naukri.com/devops-jobs-16', 'https://www.naukri.com/devops-jobs-17', 'https://www.naukri.com/devops-jobs-18', 'https://www.naukri.com/devops-jobs-19', 'https://www.naukri.com/devops-jobs-2', 'https://www.naukri.com/devops-jobs-20', 'https://www.naukri.com/devops-jobs-21', 'https://www.naukri.com/devops-jobs-22', 'https://www.naukri.com/devops-jobs-23', 'https://www.naukri.com/devops-jobs-24', 'https://www.naukri.com/devops-jobs-25', 'https://www.naukri.com/devops-jobs-26', 'https://www.naukri.com/devops-jobs-27', 'https://www.naukri.com/devops-jobs-28', 'https://www.naukri.com/devops-jobs-29', 'https://www.naukri.com/devops-jobs-3', 'https://www.naukri.com/devops-jobs-30', 'https://www.naukri.com/devops-jobs-31', 'https://www.naukri.com/devops-jobs-32', 'https://www.naukri.com/devops-jobs-33', 'https://www.naukri.com/devops-jobs-34', 'https://www.naukri.com/devops-jobs-35', 'https://www.naukri.com/devops-jobs-36', 'https://www.naukri.com/devops-jobs-37', 'https://www.naukri.com/devops-jobs-38', 'https://www.naukri.com/devops-jobs-39', 'https://www.naukri.com/devops-jobs-4', 'https://www.naukri.com/devops-jobs-40', 'https://www.naukri.com/devops-jobs-41', 'https://www.naukri.com/devops-jobs-42', 'https://www.naukri.com/devops-jobs-43', 'https://www.naukri.com/devops-jobs-44', 'https://www.naukri.com/devops-jobs-45', 'https://www.naukri.com/devops-jobs-46', 'https://www.naukri.com/devops-jobs-5', 'https://www.naukri.com/devops-jobs-6', 'https://www.naukri.com/devops-jobs-7', 'https://www.naukri.com/devops-jobs-8', 'https://www.naukri.com/devops-jobs-9']\n"
     ]
    }
   ],
   "source": [
    "# Making the URL list\n",
    "\n",
    "# Page list\n",
    "page_list = list(set(page_list))\n",
    "page_list = sorted(page_list)\n",
    "page_numbers_int = [int(digit) for digit in page_list]\n",
    "print(page_numbers_int)\n",
    "\n",
    "\n",
    "# base url\n",
    "url = 'https://www.naukri.com/devops-jobs'  # Replace with the URL of the website you want to scrape\n",
    "page_numbers_int\n",
    "# # Wait for the results page to load (you might need to adjust the waiting time)\n",
    "time.sleep(2)\n",
    "# print(page_numbers_int)\n",
    "\n",
    "final_url_list = []\n",
    "# Example: Extracting information from the results\n",
    "techstack_list =[]\n",
    "for pageid in page_list:\n",
    "    final_url = url +'-'+ str(pageid)\n",
    "    final_url_list.append(final_url)\n",
    "    \n",
    "print(final_url_list)\n",
    "\n",
    "driver.quit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DONT TOUCH Code working for capturing skills from JD's for DevOps\n",
    "# Create a new instance of the Chrome driver (or your preferred browser)\n",
    "driver = webdriver.Chrome()\n",
    "\n",
    "\n",
    "# base url\n",
    "final_url_list\n",
    "# url = 'https://www.naukri.com/devops-jobs'  # Replace with the URL of the website you want to scrape\n",
    "# driver.get(url)\n",
    "\n",
    "techstack_list =[]\n",
    "for url in final_url_list:\n",
    "    driver.get(url)\n",
    "# Wait for the results page to load (you might need to adjust the waiting time)\n",
    "    time.sleep(2)\n",
    "# Example: Extracting information from the results\n",
    "    result_elements = driver.find_elements(By.CLASS_NAME, \"dot-gt\")  # Replace with the actual locator of the result elements\n",
    "    for result in result_elements:\n",
    "        techstack = result.text\n",
    "        techstack_list.append(techstack)\n",
    "# print(techstack_list)\n",
    "\n",
    "\n",
    "# Close the browser\n",
    "driver.quit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                             0\n",
      "0                       DevOps\n",
      "1                       VMware\n",
      "2                        Nginx\n",
      "3                        JBoss\n",
      "4     Configuration management\n",
      "...                        ...\n",
      "6989                     CI/Cd\n",
      "6990                Kubernetes\n",
      "6991                    Devops\n",
      "6992              Azure Devops\n",
      "6993           Microsoft Azure\n",
      "\n",
      "[6994 rows x 1 columns]\n"
     ]
    }
   ],
   "source": [
    "#Writing to the csv\n",
    "techstack_list = pd.DataFrame(techstack_list)\n",
    "print(techstack_list)\n",
    "techstack_list.to_csv('JD-Data.csv',index=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***********************\n",
    "Data Scientist URL Creation\n",
    "***********************"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['1', '2', '3', '4', '5', '6', '7', '8', '9', '10', '1', '11', '12', '13', '14', '15', '16', '17', '18', '19', '1', '20', '21', '22', '23', '24', '25', '26', '27', '28', '1', '29', '30', '31', '32', '33', '34', '35', '36', '37', '1', '35', '36', '37', '38', '39', '40', '41']\n"
     ]
    }
   ],
   "source": [
    "\n",
    "driver = webdriver.Chrome()\n",
    "\n",
    "# Open the website\n",
    "url_DataScientist = 'https://www.naukri.com/data-scientist-jobs'  # Replace with the URL of the website you want to scrape\n",
    "driver.get(url_DataScientist)\n",
    "time.sleep(2)\n",
    "page_list_DataScientist = []\n",
    "\n",
    "# Part1\n",
    "result_div_DataScientist = driver.find_element(By.CLASS_NAME, \"styles_pages__v1rAK\")\n",
    "# Find all anchor elements within the div\n",
    "result_elements_DataScientist = result_div_DataScientist.find_elements(By.TAG_NAME, \"a\")\n",
    "# Print the text of each anchor element\n",
    "for element in result_elements_DataScientist:\n",
    "    element =element.text\n",
    "    page_list_DataScientist.append((element))\n",
    "\n",
    "\n",
    "# part2\n",
    "url_DataScientist = 'https://www.naukri.com/data-scientist-jobs-15'  # Replace with the URL of the website you want to scrape\n",
    "driver.get(url_DataScientist)\n",
    "time.sleep(2)\n",
    "result_div_DataScientist = driver.find_element(By.CLASS_NAME, \"styles_pages__v1rAK\")\n",
    "# Find all anchor elements within the div\n",
    "result_elements_DataScientist = result_div_DataScientist.find_elements(By.TAG_NAME, \"a\")\n",
    "# Print the text of each anchor element\n",
    "for element in result_elements_DataScientist:\n",
    "    element =element.text\n",
    "    page_list_DataScientist.append((element))\n",
    "\n",
    "\n",
    "# part3\n",
    "url_DataScientist = 'https://www.naukri.com/data-scientist-jobs-24'  # Replace with the URL of the website you want to scrape\n",
    "driver.get(url_DataScientist)\n",
    "time.sleep(2)\n",
    "result_div_DataScientist = driver.find_element(By.CLASS_NAME, \"styles_pages__v1rAK\")\n",
    "# Find all anchor elements within the div\n",
    "result_elements_DataScientist = result_div_DataScientist.find_elements(By.TAG_NAME, \"a\")\n",
    "# Print the text of each anchor element\n",
    "for element in result_elements_DataScientist:\n",
    "    element =element.text\n",
    "    page_list_DataScientist.append((element))\n",
    "\n",
    "# part4\n",
    "url_DataScientist = 'https://www.naukri.com/data-scientist-jobs-33'  # Replace with the URL of the website you want to scrape\n",
    "driver.get(url_DataScientist)\n",
    "time.sleep(2)\n",
    "result_div_DataScientist = driver.find_element(By.CLASS_NAME, \"styles_pages__v1rAK\")\n",
    "# Find all anchor elements within the div\n",
    "result_elements_DataScientist = result_div_DataScientist.find_elements(By.TAG_NAME, \"a\")\n",
    "# Print the text of each anchor element\n",
    "for element in result_elements_DataScientist:\n",
    "    element =element.text\n",
    "    page_list_DataScientist.append((element))\n",
    "    \n",
    "\n",
    "# part5\n",
    "url_DataScientist = 'https://www.naukri.com/data-scientist-jobs-41'  # Replace with the URL of the website you want to scrape\n",
    "driver.get(url_DataScientist)\n",
    "time.sleep(2)\n",
    "result_div_DataScientist = driver.find_element(By.CLASS_NAME, \"styles_pages__v1rAK\")\n",
    "# Find all anchor elements within the div\n",
    "result_elements_DataScientist = result_div_DataScientist.find_elements(By.TAG_NAME, \"a\")\n",
    "# Print the text of each anchor element\n",
    "for element in result_elements_DataScientist:\n",
    "    element =element.text\n",
    "    page_list_DataScientist.append((element))\n",
    "    \n",
    "\n",
    "print(page_list_DataScientist)\n",
    "\n",
    "\n",
    "driver.quit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['1', '10', '11', '12', '13', '14', '15', '16', '17', '18', '19', '2', '20', '21', '22', '23', '24', '25', '26', '27', '28', '29', '3', '30', '31', '32', '33', '34', '35', '36', '37', '38', '39', '4', '40', '41', '5', '6', '7', '8', '9']\n",
      "['https://www.naukri.com/data-scientist-jobs-1', 'https://www.naukri.com/data-scientist-jobs-10', 'https://www.naukri.com/data-scientist-jobs-11', 'https://www.naukri.com/data-scientist-jobs-12', 'https://www.naukri.com/data-scientist-jobs-13', 'https://www.naukri.com/data-scientist-jobs-14', 'https://www.naukri.com/data-scientist-jobs-15', 'https://www.naukri.com/data-scientist-jobs-16', 'https://www.naukri.com/data-scientist-jobs-17', 'https://www.naukri.com/data-scientist-jobs-18', 'https://www.naukri.com/data-scientist-jobs-19', 'https://www.naukri.com/data-scientist-jobs-2', 'https://www.naukri.com/data-scientist-jobs-20', 'https://www.naukri.com/data-scientist-jobs-21', 'https://www.naukri.com/data-scientist-jobs-22', 'https://www.naukri.com/data-scientist-jobs-23', 'https://www.naukri.com/data-scientist-jobs-24', 'https://www.naukri.com/data-scientist-jobs-25', 'https://www.naukri.com/data-scientist-jobs-26', 'https://www.naukri.com/data-scientist-jobs-27', 'https://www.naukri.com/data-scientist-jobs-28', 'https://www.naukri.com/data-scientist-jobs-29', 'https://www.naukri.com/data-scientist-jobs-3', 'https://www.naukri.com/data-scientist-jobs-30', 'https://www.naukri.com/data-scientist-jobs-31', 'https://www.naukri.com/data-scientist-jobs-32', 'https://www.naukri.com/data-scientist-jobs-33', 'https://www.naukri.com/data-scientist-jobs-34', 'https://www.naukri.com/data-scientist-jobs-35', 'https://www.naukri.com/data-scientist-jobs-36', 'https://www.naukri.com/data-scientist-jobs-37', 'https://www.naukri.com/data-scientist-jobs-38', 'https://www.naukri.com/data-scientist-jobs-39', 'https://www.naukri.com/data-scientist-jobs-4', 'https://www.naukri.com/data-scientist-jobs-40', 'https://www.naukri.com/data-scientist-jobs-41', 'https://www.naukri.com/data-scientist-jobs-5', 'https://www.naukri.com/data-scientist-jobs-6', 'https://www.naukri.com/data-scientist-jobs-7', 'https://www.naukri.com/data-scientist-jobs-8', 'https://www.naukri.com/data-scientist-jobs-9']\n"
     ]
    }
   ],
   "source": [
    "# Making the URL list\n",
    "\n",
    "# Page list\n",
    "page_list_DataScientist = list(set(page_list_DataScientist))\n",
    "page_list_DataScientist = sorted(page_list_DataScientist)\n",
    "page_list_DataScientist_int = [int(digit) for digit in page_list_DataScientist]\n",
    "print(page_list_DataScientist)\n",
    "\n",
    "\n",
    "# base url\n",
    "url = 'https://www.naukri.com/data-scientist-jobs'  # Replace with the URL of the website you want to scrape\n",
    "page_list_DataScientist\n",
    "# # Wait for the results page to load (you might need to adjust the waiting time)\n",
    "time.sleep(2)\n",
    "# print(page_numbers_int)\n",
    "\n",
    "final_url_list_DataScientist = []\n",
    "# Example: Extracting information from the results\n",
    "techstack_list =[]\n",
    "for pageid in page_list_DataScientist:\n",
    "    final_url_DataScientist = url +'-'+ str(pageid)\n",
    "    final_url_list_DataScientist.append(final_url_DataScientist)\n",
    "    \n",
    "print(final_url_list_DataScientist)\n",
    "\n",
    "driver.quit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://www.naukri.com/data-scientist-jobs-1\n",
      "https://www.naukri.com/data-scientist-jobs-10\n",
      "https://www.naukri.com/data-scientist-jobs-11\n",
      "https://www.naukri.com/data-scientist-jobs-12\n",
      "https://www.naukri.com/data-scientist-jobs-13\n",
      "https://www.naukri.com/data-scientist-jobs-14\n",
      "https://www.naukri.com/data-scientist-jobs-15\n",
      "https://www.naukri.com/data-scientist-jobs-16\n",
      "https://www.naukri.com/data-scientist-jobs-17\n",
      "https://www.naukri.com/data-scientist-jobs-18\n",
      "https://www.naukri.com/data-scientist-jobs-19\n",
      "https://www.naukri.com/data-scientist-jobs-2\n",
      "https://www.naukri.com/data-scientist-jobs-20\n",
      "https://www.naukri.com/data-scientist-jobs-21\n",
      "https://www.naukri.com/data-scientist-jobs-22\n",
      "https://www.naukri.com/data-scientist-jobs-23\n",
      "https://www.naukri.com/data-scientist-jobs-24\n",
      "https://www.naukri.com/data-scientist-jobs-25\n",
      "https://www.naukri.com/data-scientist-jobs-26\n",
      "https://www.naukri.com/data-scientist-jobs-27\n",
      "https://www.naukri.com/data-scientist-jobs-28\n",
      "https://www.naukri.com/data-scientist-jobs-29\n",
      "https://www.naukri.com/data-scientist-jobs-3\n",
      "https://www.naukri.com/data-scientist-jobs-30\n",
      "https://www.naukri.com/data-scientist-jobs-31\n",
      "https://www.naukri.com/data-scientist-jobs-32\n",
      "https://www.naukri.com/data-scientist-jobs-33\n",
      "https://www.naukri.com/data-scientist-jobs-34\n",
      "https://www.naukri.com/data-scientist-jobs-35\n",
      "https://www.naukri.com/data-scientist-jobs-36\n",
      "https://www.naukri.com/data-scientist-jobs-37\n",
      "https://www.naukri.com/data-scientist-jobs-38\n",
      "https://www.naukri.com/data-scientist-jobs-39\n",
      "https://www.naukri.com/data-scientist-jobs-4\n",
      "https://www.naukri.com/data-scientist-jobs-40\n",
      "https://www.naukri.com/data-scientist-jobs-41\n",
      "https://www.naukri.com/data-scientist-jobs-5\n",
      "https://www.naukri.com/data-scientist-jobs-6\n",
      "https://www.naukri.com/data-scientist-jobs-7\n",
      "https://www.naukri.com/data-scientist-jobs-8\n",
      "https://www.naukri.com/data-scientist-jobs-9\n",
      "['Supply chain', 'Computer science', 'SAS', 'Analytical', 'Machine learning', 'Data mining', 'MATLAB', 'Analytics', 'Computer science', 'GIT', 'GCP', 'Analytical', 'Software development life cycle', 'Workflow', 'Application development', 'Natural language processing', 'Automation', 'C++', 'Powertrain', 'Mechatronics', 'Simulation', 'Construction equipment', 'Simulink', 'MATLAB', 'Team management', 'Prototype', 'Database design', 'Agile', 'Data structures', 'MATLAB', 'Analytics', 'Financial services', 'Computer science', 'data cleansing', 'Data analysis', 'Machine learning', 'Agile', 'Data processing', 'data visualization', 'Continuous improvement', 'Supply chain', 'SAS', 'Analytical', 'Machine learning', 'Data mining', 'MATLAB', 'Analytics', 'Python', 'Neural Networks', 'Machine Learning', 'Python', 'Regression', 'Clustering', 'Data management', 'Management', 'Data', 'data science', 'Networking', 'Coding', 'Machine learning', 'SEZ', 'Instrumentation', 'big data', 'Information technology', 'Networking', 'Machine learning', 'Data structures', 'Business solutions', 'Information technology', 'Analytics', 'Monitoring', 'SQL', 'Networking', 'Machine learning', 'Data structures', 'Business solutions', 'Information technology', 'Analytics', 'Monitoring', 'SQL', 'Unix', 'Automation', 'Linux', 'Data structures', 'Perl', 'Business intelligence', 'Troubleshooting', 'Open source', 'Data Science', 'Natural Language Processing', 'data scientist', 'Machine Learning', 'Deep Learning', 'VP', 'Data', 'Machine', 'Azure', 'NLP', 'Python', 'Docker', 'FAST API', 'Data', 'API', 'Microsoft Azure', 'NLP', 'data science', 'GCP', 'Python', 'TensorFlow', 'model validation', 'PyTorch', 'BigQuery', 'Statistical modeling', 'Deployment', 'Python', 'Testing', 'Software testing', 'Data', 'Modeling', 'Statistics', 'Deep Learning', 'Python', 'SQL', 'TensorFlow', 'PyTorch', 'Data', 'Data Science', 'Artificial Intelligence Innovation', 'deep learning', 'python', 'nlp', 'client relationship', 'creative solutions', 'machine learning', 'Data Science', 'Python', 'Science', 'Data', 'Telecom', 'SAS', 'Billing', 'SQL', 'Simulation', 'SPSS', 'Business intelligence', 'Forecasting', 'CSS', 'JavaScript', 'HTML', 'React', 'open source', 'python', 'predictive modeling', 'web technologies', 'data science', 'Coding', 'Data modeling', 'Agile development', 'MySQL', 'Machine learning', 'test driven development', 'MATLAB', 'Pharma', 'Machine learning', 'Legal', 'Data processing', 'Life sciences', 'SAGE', 'Pattern recognition', 'Subject Matter Expert', 'AI', 'data science', 'Power BI', 'Access', 'RCM domain', 'SQL', 'Data modelling', 'DNS', 'machine learning', 'python', 'R', 'Hive', 'SAS', 'Sqoop', 'data mining', 'Mahout', 'Artificial intelligence', 'visualization', 'Data analysis', 'data science', 'Power BI', 'BI development', 'SQL', 'Data modelling', 'Python', 'Data Science', 'Customer Analytics', 'machine learning algorithms', 'Marketing Analytics', 'statistical methods', 'SQL', 'Methods', 'Training', 'continuous integration', 'Data analysis', 'GIT', 'Web services', 'data science', 'Artificial Intelligence', 'Machine learning', 'Natural Language Processing', 'Data Science', 'Time Series', 'Computer Vision', 'Python', 'Tensorflow', 'Big Data', 'Ml Algorithms', 'Basic', 'Data analysis', 'Version control', 'GIT', 'GCP', 'Programming', 'Healthcare', 'Technology solutions', 'Data analysis', 'Version control', 'GIT', 'data science', 'GCP', 'Analytical', 'Machine learning', 'Data mining', 'Data analysis', 'Data management', 'Postgresql', 'Analytical', 'Machine learning', 'Back office', 'Business intelligence', 'Analytics', 'Unix', 'Computer science', 'Linux', 'Coding', 'Machine learning', 'Customer service', 'Analytics', 'SQL', 'Training', 'SAN', 'Data analysis', 'Backend', 'data science', 'Machine learning', 'Venture capital', 'Equity', 'Computer science', 'Cloud computing', 'Operations research', 'Statistical analysis', 'data science', 'Machine learning', 'Data mining', 'Analytics', 'data science', 'Web analytics', 'Data modeling', 'Consulting', 'Intellectual property', 'Product strategy', 'Logistics', 'SQL', 'Data analysis', 'Data management', 'Machine learning', 'SCALA', 'Data processing', 'Data quality', 'Data mining', 'SQL', 'C++', 'Data analysis', 'SOC', 'Agile', 'Perl', 'Firmware', 'MATLAB', 'Analytics', 'IT services', 'Data analysis', 'Coding', 'Consulting', 'Machine learning', 'Data analytics', 'Digital marketing', 'SQL', 'Research', 'Data', 'Computer science', 'Prototype', 'GIT', 'Analytical', 'Machine learning', 'Information retrieval', 'Data quality', 'Forecasting', 'data science', 'GCP', 'Senior Analyst', 'Machine learning', 'Deployment', 'Mathematics', 'Predictive analytics', 'Statistics', 'SAS', 'Analytical', 'Artificial Intelligence', 'Machine learning', 'Genetics', 'data visualization', 'Information technology', 'SQL', 'Data analysis', 'MIS', 'Machine learning', 'Data quality', 'Natural language processing', 'data visualization', 'Operations', 'Analytics', 'Operations research', 'Simulation', 'Data management', 'Analytical', 'German', 'Spanish', 'Continuous improvement', 'Analytics', 'Analyst', 'data science', 'GCP', 'Machine learning', 'Deployment', 'Mathematics', 'Predictive analytics', 'Statistics', 'Statistical modeling', 'Quality improvement', 'data science', 'Artificial Intelligence', 'Machine learning', 'Open source', 'Technical support', 'Analytics', 'Computer vision', 'Performance tuning', 'deep learning', 'data science', 'Analytical', 'Machine learning', 'Packaging', 'Data structures', 'Snowflake', 'Snowpark', 'Snowpipe', 'AWS', 'Python', 'Data', 'Python', 'Stream Analytics', 'MongoDB', 'Research', 'Modeling', 'Data', 'Analytics', 'Streams', 'SAN', 'customer analytics', 'Analytical', 'Predictive modeling', 'Digital marketing', 'SQL', 'Python', 'Modeling', 'SAN', 'Data migration', 'Web services', 'Medical coding', 'Analytical', 'Data mining', 'Forecasting', 'Information technology', 'Product management', 'Quality monitoring', 'Machine learning', 'Radiology', 'Healthcare', 'Natural language processing', 'Data quality', 'Continuous improvement', 'Solution architecture', 'Data modeling', 'Machine learning', 'Data structures', 'Customer service', 'application architecture', 'Open source', 'MATLAB', 'Data analysis', 'ERP', 'Analytical', 'CMMI', 'Application development', 'MS Office', 'Data mining', 'Operations', 'Product management', 'Quality monitoring', 'Machine learning', 'Radiology', 'Healthcare', 'Natural language processing', 'Data quality', 'Continuous improvement', 'Product management', 'Quality monitoring', 'Machine learning', 'Radiology', 'Healthcare', 'Natural language processing', 'Data quality', 'Continuous improvement', 'IT services', 'MIN', 'data science', 'Finance', 'Banking', 'Science', 'Data', 'IT services', 'Analytical skills', 'deep learning', 'Statistical analysis', 'Data modeling', 'Database design', 'Analytical', 'Machine learning', 'Computer science', 'SAN', 'Analytical', 'SMS', 'Data quality', 'Business intelligence', 'Business solutions', 'Analytics', 'Machine learning', 'Data collection', 'data visualization', 'Collections', 'Data', 'Machine', 'Sports', 'MS SQL', 'data science', 'RDBMS', 'MySQL', 'Agile', 'CMMI', 'Healthcare', 'HTML', 'Elastic Search', 'Semantic search', 'Natural Language processing', 'data ingestion', 'Graph DB', 'System Integration', 'Process', 'Db', 'data cleansing', 'Operations research', 'Data modeling', 'Time series analysis', 'Machine learning', 'Software development life cycle', 'IC engines', 'Industrial machinery', 'Machine Learning', 'Predictive Modeling', 'Artificial Intelligence', 'Data science', 'Neural Networks', 'Al', 'LLM', 'Deep Learning', 'algorithms', 'data mining', 'power bi', 'MSBI', 'statistics', 'data analytics', 'Bi', 'Management', 'Python', 'database management', 'R', 'Power BI', 'GitHub', 'Data Visualization', 'Tableau', 'Statistical Analysis', 'AI', 'Machine Learning', 'Ml', 'Ai Techniques', 'Artificial Intelligence', 'Requirements', 'Machine', 'Data Science', 'R Programming', 'Linux', 'Dockers', 'AWS', 'UNIX', 'Docker', 'R Program', 'Technical product configuration', 'c++', 'C', 'design', 'MySQL', 'JavaScript', 'integration PHP', 'HTML', 'Data Science', 'python', 'data mining', 'machine learning', 'artificial intelligence', 'R', 'Statistical Analyses', 'Csharp', 'IT services', 'Logistic regression', 'Head Business Development', 'SAS', 'Machine learning', 'Vendor', 'Forecasting', 'CRM', 'Usage', 'data science', 'spark', 'Programming', 'Python', 'data', 'program', 'science', 'Web analytics', 'Coding', 'Data modeling', 'E-commerce', 'HTML', 'HR', 'Data analytics', 'Data', 'Data modeling', 'Coding', 'E-commerce', 'Predictive modeling', 'HTML', 'HR', 'Data', 'Hrsd', 'Computer science', 'Automation', 'Artificial Intelligence', 'Machine learning', 'Data collection', 'Risk management', 'Monitoring', 'SQL', 'NoSQL', 'Wealth management', 'Analytical', 'Finance', 'Machine learning', 'Programming', 'Medical insurance', 'Statistics', 'GIS', 'Image processing', 'Analytical', 'Industrial products', 'Machine learning', 'Debugging', 'Open source', 'Remote sensing', 'Computer science', 'Automation', 'Operations research', 'SAS SQL', 'Artificial Intelligence', 'Machine learning', 'MATLAB', 'Gaming', 'Computer science', 'Usage', 'Sales', 'data science', 'Machine learning', 'Revenue generation', 'SQL', 'Auditing', 'Machine learning', 'Data collection', 'data visualization', 'Data', 'Machine', 'Collections', 'Selection process', 'HP data protector', 'sophos', 'Diversity and Inclusion', 'Machine learning', 'Data quality', 'Data analytics', 'SQL', 'Pytorch', 'Natural Language Processing', 'Bert', 'Machine Learning', 'Deep Learning', 'Keras', 'Data', 'Languages', 'Mining', 'Product management', 'Cloud computing', 'data science', 'Linux', 'Machine learning', 'Oracle', 'Analytics', 'Team management', 'data science', 'Analytical', 'Consulting', 'Machine learning', 'Data processing', 'Silicon', 'Analytics', 'C++', 'PMP', 'Coding', 'Project management', 'Social media', 'Predictive modeling', 'Business solutions', 'Information technology', 'Machine Learning', 'Python', 'SQL', 'Data', 'Machine', 'Data Science', 'NLP', 'GCP', 'PySpark', 'Machine Learning', 'AWS', 'TensorFlow', 'Natural language processing', 'Data Science', 'NLP', 'PyTorch', 'LSTM', 'GCP', 'PySpark', 'ML algorithms', 'Pandas', 'Data Migration', 'Data Strategy', 'data reconciliation', 'Data Scientist', 'SAP HR Payroll', 'ETL', 'Migration', 'SAP HR', 'Computer science', 'Cloud computing', 'Computer vision', 'GCP', 'Analytical', 'Machine learning', 'data visualization', 'Reporting tools', 'deep learning', 'data science', 'Artificial Intelligence', 'Data collection', 'Packaging', 'Data analytics', 'Python', 'Testing', 'Automation', 'Data modeling', 'Analytical', 'ITSM', 'Consulting', 'ITIL', 'Financial services', 'CRM', 'Argus Safety', 'Bi Publisher', 'Oracle Argus', 'DBMS', 'Safety', 'Publishing', 'Argus', 'Bi', 'deep learning', 'Data analysis', 'Machine learning', 'Data collection', 'HTML', 'Natural language processing', 'Apache', 'SQL', 'IT services', 'Data analysis', 'data science', 'Machine learning', 'Data collection', 'Product design', 'Data mining', 'Analytics', 'Computer vision', 'Data analysis', 'Neural networks', 'Analytical', 'Artificial Intelligence', 'Machine learning', 'Data collection', 'Natural language processing', 'IT services', 'Data analysis', 'data science', 'Machine learning', 'Data collection', 'Product design', 'Data mining', 'Analytics', 'Analytical', 'Machine learning', 'Oncology', 'CME', 'data visualization', 'Digital marketing', 'SQL', 'Python', 'Data Science', 'MySQL', 'Data Analytics', 'R', 'Python', 'Analytics', 'Science', 'Data', 'C++', 'Operations research', 'Consulting', 'Video conferencing', 'Customer service', 'microsoft', 'Data mining', 'Business intelligence', 'C++', 'Operations research', 'Consulting', 'Video conferencing', 'Customer service', 'microsoft', 'Data mining', 'Business intelligence', 'Javascript', 'Deployment', 'Analytics', 'Python', 'Data', 'Linux', 'data science', 'Pharma', 'Artificial Intelligence', 'Oncology', 'Perl', 'Molecular biology', 'JIRA', 'SAS', 'Analytical', 'Consulting', 'Management consulting', 'Machine learning', 'Risk management', 'IT operations', 'Analytics', 'Graphics', 'Data analysis', 'Illustrator', 'Project management', 'Debugging', 'Animation', 'Photoshop', 'Adobe', 'Computer vision', 'Automation', 'Image processing', 'Renewable energy', 'Artificial Intelligence', 'Machine learning', 'Application development', 'Analytics', 'Computer science', 'Data analysis', 'SAS', 'Machine learning', 'Data structures', 'Data processing', 'Predictive modeling', 'Pattern recognition', 'Machine Learning', 'Statistics', 'sql', 'Data Analysis', 'Python', 'Automation', 'Query', 'simulation', 'NLP', 'Machine Learning', 'Deep Learning', 'SR', 'Machine', 'Wfo', 'Natural language processing', 'Data', 'data science', 'Analytical', 'Machine learning', 'Business case', 'SQL', 'Python', 'Analytics', 'Consumer', 'Data Science', 'Natural Language Processing', 'Deep Learning', 'Predictive Modeling', 'Neural Networks', 'Computer Vision', 'Computer', 'Languages', 'Data Science', 'Text analytics', 'Data classification', 'Regression', 'prediction', 'Machine Learning', 'Analytics', 'Science', 'Data Science', 'Machine Learning', 'Python', 'SQL', 'R', 'Big query', 'Data Analysis', 'Bigquery', 'Data Science', 'Text analytics', 'Data classification', 'python', 'tableau', 'Regression', 'prediction', 'power BI', 'Supply chain', 'Operations research', 'Automation', 'SAP', 'Analytical', 'Data collection', 'Manager Quality Control', 'Oracle', 'Machine Learning', 'Freshers', 'Data Science', 'Data Scientist', 'Java', 'C++', 'C', 'Insights', 'SAN', 'Data analysis', 'Analytical', 'Machine learning', 'Agile', 'microsoft', 'Adobe', 'Python', 'Machine learning', 'Programming', 'data visualization', 'Python', 'Data', 'Program', 'Machine', 'python', 'Ml', 'Artificial Intelligence', 'Aiml', 'Intelligence', 'Computer science', 'Operations research', 'Version control', 'GIT', 'Artificial Intelligence', 'Machine learning', 'Operations', 'Analytics', 'Machine learning', 'Data collection', 'Programming', 'data visualization', 'Data mining', 'Risk management', 'MATLAB', 'Statistics', 'Data scientist', 'pandas', 'Python', 'SQL', 'azure', 'Numpy', 'Data', 'Microsoft Azure', 'Unix', 'Product management', 'Computer science', 'GIT', 'Machine learning', 'Workflow', 'Licensing', 'microsoft', 'Unix', 'Product management', 'Computer science', 'GIT', 'data science', 'Machine learning', 'Technical leadership', 'Workflow', 'Data validation', 'Machine learning', 'Information retrieval', 'Data quality', 'Business intelligence', 'Forecasting', 'Operations', 'Analytics', 'Data analysis', 'data science', 'GCP', 'Business analytics', 'Artificial Intelligence', 'Machine learning', 'Continuous improvement', 'SQL', 'data science', 'Advance data analytics', 'machine learning', 'Business analysis', 'Business analytics', 'Analytics', 'Data', 'Machine', 'Usage', 'data science', 'Analytical', 'Machine learning', 'Business case', 'SQL', 'Python', 'Science', 'Claims', 'Coding', 'Underwriting', 'Analytical', 'Asset management', 'Analytics', 'Financial services', 'SQL', 'data cleansing', 'Logistic regression', 'Analytical', 'Machine learning', 'linear regression', 'Healthcare', 'Data mining', 'SQL', 'Data Science', 'Data Scientist', 'Deep Learning', 'LLAMA', 'Neural Networks', 'GPT', 'BERT', 'Data', 'Computer science', 'E-learning', 'SAN', 'Data analysis', 'French', 'Analytical', 'Research Associate', 'Internship', 'Logistic regression', 'Data analysis', 'data science', 'Bfsi', 'Analytical', 'linear regression', 'SPSS', 'Asset management', 'Computer science', 'C++', 'Analytical', 'Social media', 'Formulation', 'Teradata', 'Forecasting', 'Analytics', 'Python', 'Data', 'Computer science', 'Cloud computing', 'Computer vision', 'deep learning', 'Neural networks', 'Analytical', 'Artificial Intelligence', 'Data processing', 'Computer science', 'Data analysis', 'data science', 'Machine learning', 'SCALA', 'Data collection', 'Predictive modeling', 'data visualization', 'data cleansing', 'Text mining', 'Simulation', 'Network analysis', 'Machine learning', 'Agile', 'Predictive modeling', 'Data mining']\n"
     ]
    }
   ],
   "source": [
    "# DONT TOUCH Code working for capturing skills from JD's for Data Scientist\n",
    "# Create a new instance of the Chrome driver (or your preferred browser)\n",
    "driver = webdriver.Chrome()\n",
    "\n",
    "\n",
    "# base url\n",
    "final_url_list_DataScientist\n",
    "# url = 'https://www.naukri.com/devops-jobs'  # Replace with the URL of the website you want to scrape\n",
    "# driver.get(url)\n",
    "\n",
    "techstack_list_DataScientist =[]\n",
    "for url_DataScientist in final_url_list_DataScientist:\n",
    "    print(url_DataScientist)\n",
    "    driver.get(url_DataScientist)\n",
    "# Wait for the results page to load (you might need to adjust the waiting time)\n",
    "    time.sleep(2)\n",
    "# Example: Extracting information from the results\n",
    "    result_elements_DataScientist = driver.find_elements(By.CLASS_NAME, \"dot-gt\")  # Replace with the actual locator of the result elements\n",
    "    for result in result_elements_DataScientist:\n",
    "        techstack_DataScientist = result.text\n",
    "        techstack_list_DataScientist.append(techstack_DataScientist)\n",
    "print(techstack_list_DataScientist)\n",
    "\n",
    "\n",
    "# Close the browser\n",
    "driver.quit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                        0\n",
      "0            Supply chain\n",
      "1        Computer science\n",
      "2                     SAS\n",
      "3              Analytical\n",
      "4        Machine learning\n",
      "...                   ...\n",
      "1064     Network analysis\n",
      "1065     Machine learning\n",
      "1066                Agile\n",
      "1067  Predictive modeling\n",
      "1068          Data mining\n",
      "\n",
      "[1069 rows x 1 columns]\n"
     ]
    }
   ],
   "source": [
    "#Writing to the csv\n",
    "techstack_list_DataScientist = pd.DataFrame(techstack_list_DataScientist)\n",
    "print(techstack_list_DataScientist)\n",
    "techstack_list_DataScientist.to_csv('JD-Data_DataScientist.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

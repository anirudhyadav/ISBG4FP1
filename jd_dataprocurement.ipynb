{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "import selenium\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.chrome.service import Service as ChromeService\n",
    "# brew install chromedriver \n",
    "\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "from selenium.webdriver.common.by import By\n",
    "import time\n",
    "import re\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "********************\n",
    "JD's related data procurement\n",
    "********************"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***********************\n",
    "DEVOPS URL Create\n",
    "***********************"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "driver = webdriver.Chrome()\n",
    "\n",
    "# Open the website\n",
    "url = 'https://www.naukri.com/devops-jobs'  # Replace with the URL of the website you want to scrape\n",
    "driver.get(url)\n",
    "time.sleep(2)\n",
    "page_list = []\n",
    "\n",
    "# Part1\n",
    "result_div = driver.find_element(By.CLASS_NAME, \"styles_pages__v1rAK\")\n",
    "\n",
    "# Find all anchor elements within the div\n",
    "result_elements = result_div.find_elements(By.TAG_NAME, \"a\")\n",
    "\n",
    "# Print the text of each anchor element\n",
    "for element in result_elements:\n",
    "    element =element.text\n",
    "    page_list.append((element))\n",
    "\n",
    "\n",
    "# part2\n",
    "url = 'https://www.naukri.com/devops-jobs-15'  # Replace with the URL of the website you want to scrape\n",
    "driver.get(url)\n",
    "time.sleep(2)\n",
    "result_div = driver.find_element(By.CLASS_NAME, \"styles_pages__v1rAK\")\n",
    "# Find all anchor elements within the div\n",
    "result_elements = result_div.find_elements(By.TAG_NAME, \"a\")\n",
    "# Print the text of each anchor element\n",
    "for element in result_elements:\n",
    "    element =element.text\n",
    "    page_list.append((element))\n",
    "\n",
    "\n",
    "# part3\n",
    "url = 'https://www.naukri.com/devops-jobs-24'  # Replace with the URL of the website you want to scrape\n",
    "driver.get(url)\n",
    "time.sleep(2)\n",
    "result_div = driver.find_element(By.CLASS_NAME, \"styles_pages__v1rAK\")\n",
    "# Find all anchor elements within the div\n",
    "result_elements = result_div.find_elements(By.TAG_NAME, \"a\")\n",
    "# Print the text of each anchor element\n",
    "for element in result_elements:\n",
    "    element =element.text\n",
    "    page_list.append((element))\n",
    "\n",
    "# part4\n",
    "url = 'https://www.naukri.com/devops-jobs-33'  # Replace with the URL of the website you want to scrape\n",
    "driver.get(url)\n",
    "time.sleep(2)\n",
    "result_div = driver.find_element(By.CLASS_NAME, \"styles_pages__v1rAK\")\n",
    "# Find all anchor elements within the div\n",
    "result_elements = result_div.find_elements(By.TAG_NAME, \"a\")\n",
    "# Print the text of each anchor element\n",
    "for element in result_elements:\n",
    "    element =element.text\n",
    "    page_list.append((element))\n",
    "    \n",
    "\n",
    "# part5\n",
    "url = 'https://www.naukri.com/devops-jobs-42'  # Replace with the URL of the website you want to scrape\n",
    "driver.get(url)\n",
    "time.sleep(2)\n",
    "result_div = driver.find_element(By.CLASS_NAME, \"styles_pages__v1rAK\")\n",
    "# Find all anchor elements within the div\n",
    "result_elements = result_div.find_elements(By.TAG_NAME, \"a\")\n",
    "# Print the text of each anchor element\n",
    "for element in result_elements:\n",
    "    element =element.text\n",
    "    page_list.append((element))\n",
    "    \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "driver.quit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 2, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 3, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 4, 40, 41, 42, 43, 44, 45, 46, 5, 6, 7, 8, 9]\n",
      "['https://www.naukri.com/devops-jobs-1', 'https://www.naukri.com/devops-jobs-10', 'https://www.naukri.com/devops-jobs-11', 'https://www.naukri.com/devops-jobs-12', 'https://www.naukri.com/devops-jobs-13', 'https://www.naukri.com/devops-jobs-14', 'https://www.naukri.com/devops-jobs-15', 'https://www.naukri.com/devops-jobs-16', 'https://www.naukri.com/devops-jobs-17', 'https://www.naukri.com/devops-jobs-18', 'https://www.naukri.com/devops-jobs-19', 'https://www.naukri.com/devops-jobs-2', 'https://www.naukri.com/devops-jobs-20', 'https://www.naukri.com/devops-jobs-21', 'https://www.naukri.com/devops-jobs-22', 'https://www.naukri.com/devops-jobs-23', 'https://www.naukri.com/devops-jobs-24', 'https://www.naukri.com/devops-jobs-25', 'https://www.naukri.com/devops-jobs-26', 'https://www.naukri.com/devops-jobs-27', 'https://www.naukri.com/devops-jobs-28', 'https://www.naukri.com/devops-jobs-29', 'https://www.naukri.com/devops-jobs-3', 'https://www.naukri.com/devops-jobs-30', 'https://www.naukri.com/devops-jobs-31', 'https://www.naukri.com/devops-jobs-32', 'https://www.naukri.com/devops-jobs-33', 'https://www.naukri.com/devops-jobs-34', 'https://www.naukri.com/devops-jobs-35', 'https://www.naukri.com/devops-jobs-36', 'https://www.naukri.com/devops-jobs-37', 'https://www.naukri.com/devops-jobs-38', 'https://www.naukri.com/devops-jobs-39', 'https://www.naukri.com/devops-jobs-4', 'https://www.naukri.com/devops-jobs-40', 'https://www.naukri.com/devops-jobs-41', 'https://www.naukri.com/devops-jobs-42', 'https://www.naukri.com/devops-jobs-43', 'https://www.naukri.com/devops-jobs-44', 'https://www.naukri.com/devops-jobs-45', 'https://www.naukri.com/devops-jobs-46', 'https://www.naukri.com/devops-jobs-5', 'https://www.naukri.com/devops-jobs-6', 'https://www.naukri.com/devops-jobs-7', 'https://www.naukri.com/devops-jobs-8', 'https://www.naukri.com/devops-jobs-9']\n"
     ]
    }
   ],
   "source": [
    "# Making the URL list\n",
    "\n",
    "# Page list\n",
    "page_list = list(set(page_list))\n",
    "page_list = sorted(page_list)\n",
    "page_numbers_int = [int(digit) for digit in page_list]\n",
    "print(page_numbers_int)\n",
    "\n",
    "\n",
    "# base url\n",
    "url = 'https://www.naukri.com/devops-jobs'  # Replace with the URL of the website you want to scrape\n",
    "page_numbers_int\n",
    "# # Wait for the results page to load (you might need to adjust the waiting time)\n",
    "time.sleep(2)\n",
    "# print(page_numbers_int)\n",
    "\n",
    "final_url_list = []\n",
    "# Example: Extracting information from the results\n",
    "techstack_list =[]\n",
    "for pageid in page_list:\n",
    "    final_url = url +'-'+ str(pageid)\n",
    "    final_url_list.append(final_url)\n",
    "    \n",
    "print(final_url_list)\n",
    "\n",
    "driver.quit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DONT TOUCH Code working for capturing skills from JD's for DevOps\n",
    "# Create a new instance of the Chrome driver (or your preferred browser)\n",
    "driver = webdriver.Chrome()\n",
    "\n",
    "\n",
    "# base url\n",
    "final_url_list\n",
    "\n",
    "techstack_list =[]\n",
    "for url in final_url_list:\n",
    "    driver.get(url)\n",
    "# Wait for the results page to load (you might need to adjust the waiting time)\n",
    "    time.sleep(2)\n",
    "# Example: Extracting information from the results\n",
    "    result_elements = driver.find_elements(By.CLASS_NAME, \"dot-gt\")  # Replace with the actual locator of the result elements\n",
    "    for result in result_elements:\n",
    "        techstack = result.text\n",
    "        techstack_list.append(techstack)\n",
    "# print(techstack_list)\n",
    "\n",
    "\n",
    "# Close the browser\n",
    "driver.quit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                             0                    Skills JobType\n",
      "0                       DevOps                    DevOps      DO\n",
      "1                       VMware                    VMware      DO\n",
      "2                        Nginx                     Nginx      DO\n",
      "3                        JBoss                     JBoss      DO\n",
      "4     Configuration management  Configuration management      DO\n",
      "...                        ...                       ...     ...\n",
      "2816                   Jenkins                   Jenkins      DO\n",
      "2817                 Terraform                 Terraform      DO\n",
      "2818                   Ansible                   Ansible      DO\n",
      "2819             Cicd Pipeline             Cicd Pipeline      DO\n",
      "2820                  Pipeline                  Pipeline      DO\n",
      "\n",
      "[2821 rows x 3 columns]\n"
     ]
    }
   ],
   "source": [
    "#Writing to the csv\n",
    "techstack_list_w = techstack_list\n",
    "\n",
    "techstack_list_w = pd.DataFrame(techstack_list_w)\n",
    "techstack_list_w['Skills'] =techstack_list_w\n",
    "test = 'DO'\n",
    "techstack_list_w['JobType'] = test\n",
    "# techstack_list_w = techstack_list_w.drop(techstack_list_w.columns[0], axis=1)\n",
    "print(techstack_list_w)\n",
    "techstack_list_w.to_csv('JD-Data.csv',index=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***********************\n",
    "Data Scientist URL Creation\n",
    "***********************"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['1', '2', '3', '4', '5', '6', '7', '8', '9', '10', '1', '11', '12', '13', '14', '15', '16', '17', '18', '19', '1', '20', '21', '22', '23', '24', '25', '26', '27', '28', '1', '29', '30', '31', '32', '33', '34', '35', '36', '37', '1', '35', '36', '37', '38', '39', '40', '41']\n"
     ]
    }
   ],
   "source": [
    "\n",
    "driver = webdriver.Chrome()\n",
    "\n",
    "# Open the website\n",
    "url_DataScientist = 'https://www.naukri.com/data-scientist-jobs'  # Replace with the URL of the website you want to scrape\n",
    "driver.get(url_DataScientist)\n",
    "time.sleep(2)\n",
    "page_list_DataScientist = []\n",
    "\n",
    "# Part1\n",
    "result_div_DataScientist = driver.find_element(By.CLASS_NAME, \"styles_pages__v1rAK\")\n",
    "# Find all anchor elements within the div\n",
    "result_elements_DataScientist = result_div_DataScientist.find_elements(By.TAG_NAME, \"a\")\n",
    "# Print the text of each anchor element\n",
    "for element in result_elements_DataScientist:\n",
    "    element =element.text\n",
    "    page_list_DataScientist.append((element))\n",
    "\n",
    "\n",
    "# part2\n",
    "url_DataScientist = 'https://www.naukri.com/data-scientist-jobs-15'  # Replace with the URL of the website you want to scrape\n",
    "driver.get(url_DataScientist)\n",
    "time.sleep(2)\n",
    "result_div_DataScientist = driver.find_element(By.CLASS_NAME, \"styles_pages__v1rAK\")\n",
    "# Find all anchor elements within the div\n",
    "result_elements_DataScientist = result_div_DataScientist.find_elements(By.TAG_NAME, \"a\")\n",
    "# Print the text of each anchor element\n",
    "for element in result_elements_DataScientist:\n",
    "    element =element.text\n",
    "    page_list_DataScientist.append((element))\n",
    "\n",
    "\n",
    "# part3\n",
    "url_DataScientist = 'https://www.naukri.com/data-scientist-jobs-24'  # Replace with the URL of the website you want to scrape\n",
    "driver.get(url_DataScientist)\n",
    "time.sleep(2)\n",
    "result_div_DataScientist = driver.find_element(By.CLASS_NAME, \"styles_pages__v1rAK\")\n",
    "# Find all anchor elements within the div\n",
    "result_elements_DataScientist = result_div_DataScientist.find_elements(By.TAG_NAME, \"a\")\n",
    "# Print the text of each anchor element\n",
    "for element in result_elements_DataScientist:\n",
    "    element =element.text\n",
    "    page_list_DataScientist.append((element))\n",
    "\n",
    "# part4\n",
    "url_DataScientist = 'https://www.naukri.com/data-scientist-jobs-33'  # Replace with the URL of the website you want to scrape\n",
    "driver.get(url_DataScientist)\n",
    "time.sleep(2)\n",
    "result_div_DataScientist = driver.find_element(By.CLASS_NAME, \"styles_pages__v1rAK\")\n",
    "# Find all anchor elements within the div\n",
    "result_elements_DataScientist = result_div_DataScientist.find_elements(By.TAG_NAME, \"a\")\n",
    "# Print the text of each anchor element\n",
    "for element in result_elements_DataScientist:\n",
    "    element =element.text\n",
    "    page_list_DataScientist.append((element))\n",
    "    \n",
    "\n",
    "# part5\n",
    "url_DataScientist = 'https://www.naukri.com/data-scientist-jobs-41'  # Replace with the URL of the website you want to scrape\n",
    "driver.get(url_DataScientist)\n",
    "time.sleep(2)\n",
    "result_div_DataScientist = driver.find_element(By.CLASS_NAME, \"styles_pages__v1rAK\")\n",
    "# Find all anchor elements within the div\n",
    "result_elements_DataScientist = result_div_DataScientist.find_elements(By.TAG_NAME, \"a\")\n",
    "# Print the text of each anchor element\n",
    "for element in result_elements_DataScientist:\n",
    "    element =element.text\n",
    "    page_list_DataScientist.append((element))\n",
    "    \n",
    "\n",
    "print(page_list_DataScientist)\n",
    "\n",
    "\n",
    "driver.quit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['1', '10', '11', '12', '13', '14', '15', '16', '17', '18', '19', '2', '20', '21', '22', '23', '24', '25', '26', '27', '28', '29', '3', '30', '31', '32', '33', '34', '35', '36', '37', '38', '39', '4', '40', '41', '5', '6', '7', '8', '9']\n",
      "['https://www.naukri.com/data-scientist-jobs-1', 'https://www.naukri.com/data-scientist-jobs-10', 'https://www.naukri.com/data-scientist-jobs-11', 'https://www.naukri.com/data-scientist-jobs-12', 'https://www.naukri.com/data-scientist-jobs-13', 'https://www.naukri.com/data-scientist-jobs-14', 'https://www.naukri.com/data-scientist-jobs-15', 'https://www.naukri.com/data-scientist-jobs-16', 'https://www.naukri.com/data-scientist-jobs-17', 'https://www.naukri.com/data-scientist-jobs-18', 'https://www.naukri.com/data-scientist-jobs-19', 'https://www.naukri.com/data-scientist-jobs-2', 'https://www.naukri.com/data-scientist-jobs-20', 'https://www.naukri.com/data-scientist-jobs-21', 'https://www.naukri.com/data-scientist-jobs-22', 'https://www.naukri.com/data-scientist-jobs-23', 'https://www.naukri.com/data-scientist-jobs-24', 'https://www.naukri.com/data-scientist-jobs-25', 'https://www.naukri.com/data-scientist-jobs-26', 'https://www.naukri.com/data-scientist-jobs-27', 'https://www.naukri.com/data-scientist-jobs-28', 'https://www.naukri.com/data-scientist-jobs-29', 'https://www.naukri.com/data-scientist-jobs-3', 'https://www.naukri.com/data-scientist-jobs-30', 'https://www.naukri.com/data-scientist-jobs-31', 'https://www.naukri.com/data-scientist-jobs-32', 'https://www.naukri.com/data-scientist-jobs-33', 'https://www.naukri.com/data-scientist-jobs-34', 'https://www.naukri.com/data-scientist-jobs-35', 'https://www.naukri.com/data-scientist-jobs-36', 'https://www.naukri.com/data-scientist-jobs-37', 'https://www.naukri.com/data-scientist-jobs-38', 'https://www.naukri.com/data-scientist-jobs-39', 'https://www.naukri.com/data-scientist-jobs-4', 'https://www.naukri.com/data-scientist-jobs-40', 'https://www.naukri.com/data-scientist-jobs-41', 'https://www.naukri.com/data-scientist-jobs-5', 'https://www.naukri.com/data-scientist-jobs-6', 'https://www.naukri.com/data-scientist-jobs-7', 'https://www.naukri.com/data-scientist-jobs-8', 'https://www.naukri.com/data-scientist-jobs-9']\n"
     ]
    }
   ],
   "source": [
    "# Making the URL list\n",
    "\n",
    "# Page list\n",
    "page_list_DataScientist = list(set(page_list_DataScientist))\n",
    "page_list_DataScientist = sorted(page_list_DataScientist)\n",
    "page_list_DataScientist_int = [int(digit) for digit in page_list_DataScientist]\n",
    "print(page_list_DataScientist)\n",
    "\n",
    "\n",
    "# base url\n",
    "url = 'https://www.naukri.com/data-scientist-jobs'  # Replace with the URL of the website you want to scrape\n",
    "page_list_DataScientist\n",
    "# # Wait for the results page to load (you might need to adjust the waiting time)\n",
    "time.sleep(2)\n",
    "# print(page_numbers_int)\n",
    "\n",
    "final_url_list_DataScientist = []\n",
    "# Example: Extracting information from the results\n",
    "techstack_list =[]\n",
    "for pageid in page_list_DataScientist:\n",
    "    final_url_DataScientist = url +'-'+ str(pageid)\n",
    "    final_url_list_DataScientist.append(final_url_DataScientist)\n",
    "    \n",
    "print(final_url_list_DataScientist)\n",
    "\n",
    "driver.quit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DONT TOUCH Code working for capturing skills from JD's for Data Scientist\n",
    "# Create a new instance of the Chrome driver (or your preferred browser)\n",
    "driver = webdriver.Chrome()\n",
    "\n",
    "\n",
    "# base url\n",
    "final_url_list_DataScientist\n",
    "# url = 'https://www.naukri.com/devops-jobs'  # Replace with the URL of the website you want to scrape\n",
    "# driver.get(url)\n",
    "\n",
    "techstack_list_DataScientist =[]\n",
    "for url_DataScientist in final_url_list_DataScientist:\n",
    "    # print(url_DataScientist)\n",
    "    driver.get(url_DataScientist)\n",
    "# Wait for the results page to load (you might need to adjust the waiting time)\n",
    "    time.sleep(2)\n",
    "# Example: Extracting information from the results\n",
    "    result_elements_DataScientist = driver.find_elements(By.CLASS_NAME, \"dot-gt\")  # Replace with the actual locator of the result elements\n",
    "    for result in result_elements_DataScientist:\n",
    "        techstack_DataScientist = result.text\n",
    "        techstack_list_DataScientist.append(techstack_DataScientist)\n",
    "# print(techstack_list_DataScientist)\n",
    "\n",
    "\n",
    "# Close the browser\n",
    "driver.quit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "               Skills JobType\n",
      "0     Computer vision      DS\n",
      "1                 C++      DS\n",
      "2    Image processing      DS\n",
      "3        data science      DS\n",
      "4               Agile      DS\n",
      "..                ...     ...\n",
      "620                AI      DS\n",
      "621          power bi      DS\n",
      "622    BI development      DS\n",
      "623        dashboards      DS\n",
      "624               sql      DS\n",
      "\n",
      "[625 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "#Writing to the csv\n",
    "techstack_list_DataScientist_w= techstack_list_DataScientist\n",
    "techstack_list_DataScientist_w = pd.DataFrame(techstack_list_DataScientist_w)\n",
    "techstack_list_DataScientist_w['Skills'] = techstack_list_DataScientist_w\n",
    "test = 'DS'\n",
    "techstack_list_DataScientist_w['JobType'] = test\n",
    "techstack_list_DataScientist_w = techstack_list_DataScientist_w.drop(techstack_list_DataScientist_w.columns[0], axis=1)\n",
    "print(techstack_list_DataScientist_w)\n",
    "techstack_list_DataScientist_w.to_csv('JD-Data_DataScientist.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "import selenium\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.chrome.service import Service as ChromeService\n",
    "# brew install chromedriver \n",
    "\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "from selenium.webdriver.common.by import By\n",
    "import time\n",
    "import re\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "********************\n",
    "JD's related data procurement\n",
    "********************"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***********************\n",
    "DEVOPS URL Create\n",
    "***********************"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['1', '2', '3', '4', '5', '6', '7', '8', '9', '10', '1', '11', '12', '13', '14', '15', '16', '17', '18', '19', '1', '20', '21', '22', '23', '24', '25', '26', '27', '28', '1', '29', '30', '31', '32', '33', '34', '35', '36', '37', '1', '38', '39', '40', '41', '42', '43', '44', '45', '46']\n"
     ]
    }
   ],
   "source": [
    "\n",
    "driver = webdriver.Chrome()\n",
    "\n",
    "# Open the website\n",
    "url = 'https://www.naukri.com/devops-jobs'  # Replace with the URL of the website you want to scrape\n",
    "driver.get(url)\n",
    "time.sleep(2)\n",
    "page_list = []\n",
    "\n",
    "# Part1\n",
    "result_div = driver.find_element(By.CLASS_NAME, \"styles_pages__v1rAK\")\n",
    "\n",
    "# Find all anchor elements within the div\n",
    "result_elements = result_div.find_elements(By.TAG_NAME, \"a\")\n",
    "\n",
    "# Print the text of each anchor element\n",
    "for element in result_elements:\n",
    "    element =element.text\n",
    "    page_list.append((element))\n",
    "\n",
    "\n",
    "# part2\n",
    "url = 'https://www.naukri.com/devops-jobs-15'  # Replace with the URL of the website you want to scrape\n",
    "driver.get(url)\n",
    "time.sleep(2)\n",
    "result_div = driver.find_element(By.CLASS_NAME, \"styles_pages__v1rAK\")\n",
    "# Find all anchor elements within the div\n",
    "result_elements = result_div.find_elements(By.TAG_NAME, \"a\")\n",
    "# Print the text of each anchor element\n",
    "for element in result_elements:\n",
    "    element =element.text\n",
    "    page_list.append((element))\n",
    "\n",
    "\n",
    "# part3\n",
    "url = 'https://www.naukri.com/devops-jobs-24'  # Replace with the URL of the website you want to scrape\n",
    "driver.get(url)\n",
    "time.sleep(2)\n",
    "result_div = driver.find_element(By.CLASS_NAME, \"styles_pages__v1rAK\")\n",
    "# Find all anchor elements within the div\n",
    "result_elements = result_div.find_elements(By.TAG_NAME, \"a\")\n",
    "# Print the text of each anchor element\n",
    "for element in result_elements:\n",
    "    element =element.text\n",
    "    page_list.append((element))\n",
    "\n",
    "# part4\n",
    "url = 'https://www.naukri.com/devops-jobs-33'  # Replace with the URL of the website you want to scrape\n",
    "driver.get(url)\n",
    "time.sleep(2)\n",
    "result_div = driver.find_element(By.CLASS_NAME, \"styles_pages__v1rAK\")\n",
    "# Find all anchor elements within the div\n",
    "result_elements = result_div.find_elements(By.TAG_NAME, \"a\")\n",
    "# Print the text of each anchor element\n",
    "for element in result_elements:\n",
    "    element =element.text\n",
    "    page_list.append((element))\n",
    "    \n",
    "\n",
    "# part5\n",
    "url = 'https://www.naukri.com/devops-jobs-42'  # Replace with the URL of the website you want to scrape\n",
    "driver.get(url)\n",
    "time.sleep(2)\n",
    "result_div = driver.find_element(By.CLASS_NAME, \"styles_pages__v1rAK\")\n",
    "# Find all anchor elements within the div\n",
    "result_elements = result_div.find_elements(By.TAG_NAME, \"a\")\n",
    "# Print the text of each anchor element\n",
    "for element in result_elements:\n",
    "    element =element.text\n",
    "    page_list.append((element))\n",
    "    \n",
    "print(page_list)\n",
    "\n",
    "driver.quit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 2, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 3, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 4, 40, 41, 42, 43, 44, 45, 46, 5, 6, 7, 8, 9]\n",
      "['https://www.naukri.com/devops-jobs-1?ctcFilter=0to3&ctcFilter=3to6&ctcFilter=6to10&ctcFilter=10to15&ctcFilter=15to25&ctcFilter=25', 'https://www.naukri.com/devops-jobs-10?ctcFilter=0to3&ctcFilter=3to6&ctcFilter=6to10&ctcFilter=10to15&ctcFilter=15to25&ctcFilter=25', 'https://www.naukri.com/devops-jobs-11?ctcFilter=0to3&ctcFilter=3to6&ctcFilter=6to10&ctcFilter=10to15&ctcFilter=15to25&ctcFilter=25', 'https://www.naukri.com/devops-jobs-12?ctcFilter=0to3&ctcFilter=3to6&ctcFilter=6to10&ctcFilter=10to15&ctcFilter=15to25&ctcFilter=25', 'https://www.naukri.com/devops-jobs-13?ctcFilter=0to3&ctcFilter=3to6&ctcFilter=6to10&ctcFilter=10to15&ctcFilter=15to25&ctcFilter=25', 'https://www.naukri.com/devops-jobs-14?ctcFilter=0to3&ctcFilter=3to6&ctcFilter=6to10&ctcFilter=10to15&ctcFilter=15to25&ctcFilter=25', 'https://www.naukri.com/devops-jobs-15?ctcFilter=0to3&ctcFilter=3to6&ctcFilter=6to10&ctcFilter=10to15&ctcFilter=15to25&ctcFilter=25', 'https://www.naukri.com/devops-jobs-16?ctcFilter=0to3&ctcFilter=3to6&ctcFilter=6to10&ctcFilter=10to15&ctcFilter=15to25&ctcFilter=25', 'https://www.naukri.com/devops-jobs-17?ctcFilter=0to3&ctcFilter=3to6&ctcFilter=6to10&ctcFilter=10to15&ctcFilter=15to25&ctcFilter=25', 'https://www.naukri.com/devops-jobs-18?ctcFilter=0to3&ctcFilter=3to6&ctcFilter=6to10&ctcFilter=10to15&ctcFilter=15to25&ctcFilter=25', 'https://www.naukri.com/devops-jobs-19?ctcFilter=0to3&ctcFilter=3to6&ctcFilter=6to10&ctcFilter=10to15&ctcFilter=15to25&ctcFilter=25', 'https://www.naukri.com/devops-jobs-2?ctcFilter=0to3&ctcFilter=3to6&ctcFilter=6to10&ctcFilter=10to15&ctcFilter=15to25&ctcFilter=25', 'https://www.naukri.com/devops-jobs-20?ctcFilter=0to3&ctcFilter=3to6&ctcFilter=6to10&ctcFilter=10to15&ctcFilter=15to25&ctcFilter=25', 'https://www.naukri.com/devops-jobs-21?ctcFilter=0to3&ctcFilter=3to6&ctcFilter=6to10&ctcFilter=10to15&ctcFilter=15to25&ctcFilter=25', 'https://www.naukri.com/devops-jobs-22?ctcFilter=0to3&ctcFilter=3to6&ctcFilter=6to10&ctcFilter=10to15&ctcFilter=15to25&ctcFilter=25', 'https://www.naukri.com/devops-jobs-23?ctcFilter=0to3&ctcFilter=3to6&ctcFilter=6to10&ctcFilter=10to15&ctcFilter=15to25&ctcFilter=25', 'https://www.naukri.com/devops-jobs-24?ctcFilter=0to3&ctcFilter=3to6&ctcFilter=6to10&ctcFilter=10to15&ctcFilter=15to25&ctcFilter=25', 'https://www.naukri.com/devops-jobs-25?ctcFilter=0to3&ctcFilter=3to6&ctcFilter=6to10&ctcFilter=10to15&ctcFilter=15to25&ctcFilter=25', 'https://www.naukri.com/devops-jobs-26?ctcFilter=0to3&ctcFilter=3to6&ctcFilter=6to10&ctcFilter=10to15&ctcFilter=15to25&ctcFilter=25', 'https://www.naukri.com/devops-jobs-27?ctcFilter=0to3&ctcFilter=3to6&ctcFilter=6to10&ctcFilter=10to15&ctcFilter=15to25&ctcFilter=25', 'https://www.naukri.com/devops-jobs-28?ctcFilter=0to3&ctcFilter=3to6&ctcFilter=6to10&ctcFilter=10to15&ctcFilter=15to25&ctcFilter=25', 'https://www.naukri.com/devops-jobs-29?ctcFilter=0to3&ctcFilter=3to6&ctcFilter=6to10&ctcFilter=10to15&ctcFilter=15to25&ctcFilter=25', 'https://www.naukri.com/devops-jobs-3?ctcFilter=0to3&ctcFilter=3to6&ctcFilter=6to10&ctcFilter=10to15&ctcFilter=15to25&ctcFilter=25', 'https://www.naukri.com/devops-jobs-30?ctcFilter=0to3&ctcFilter=3to6&ctcFilter=6to10&ctcFilter=10to15&ctcFilter=15to25&ctcFilter=25', 'https://www.naukri.com/devops-jobs-31?ctcFilter=0to3&ctcFilter=3to6&ctcFilter=6to10&ctcFilter=10to15&ctcFilter=15to25&ctcFilter=25', 'https://www.naukri.com/devops-jobs-32?ctcFilter=0to3&ctcFilter=3to6&ctcFilter=6to10&ctcFilter=10to15&ctcFilter=15to25&ctcFilter=25', 'https://www.naukri.com/devops-jobs-33?ctcFilter=0to3&ctcFilter=3to6&ctcFilter=6to10&ctcFilter=10to15&ctcFilter=15to25&ctcFilter=25', 'https://www.naukri.com/devops-jobs-34?ctcFilter=0to3&ctcFilter=3to6&ctcFilter=6to10&ctcFilter=10to15&ctcFilter=15to25&ctcFilter=25', 'https://www.naukri.com/devops-jobs-35?ctcFilter=0to3&ctcFilter=3to6&ctcFilter=6to10&ctcFilter=10to15&ctcFilter=15to25&ctcFilter=25', 'https://www.naukri.com/devops-jobs-36?ctcFilter=0to3&ctcFilter=3to6&ctcFilter=6to10&ctcFilter=10to15&ctcFilter=15to25&ctcFilter=25', 'https://www.naukri.com/devops-jobs-37?ctcFilter=0to3&ctcFilter=3to6&ctcFilter=6to10&ctcFilter=10to15&ctcFilter=15to25&ctcFilter=25', 'https://www.naukri.com/devops-jobs-38?ctcFilter=0to3&ctcFilter=3to6&ctcFilter=6to10&ctcFilter=10to15&ctcFilter=15to25&ctcFilter=25', 'https://www.naukri.com/devops-jobs-39?ctcFilter=0to3&ctcFilter=3to6&ctcFilter=6to10&ctcFilter=10to15&ctcFilter=15to25&ctcFilter=25', 'https://www.naukri.com/devops-jobs-4?ctcFilter=0to3&ctcFilter=3to6&ctcFilter=6to10&ctcFilter=10to15&ctcFilter=15to25&ctcFilter=25', 'https://www.naukri.com/devops-jobs-40?ctcFilter=0to3&ctcFilter=3to6&ctcFilter=6to10&ctcFilter=10to15&ctcFilter=15to25&ctcFilter=25', 'https://www.naukri.com/devops-jobs-41?ctcFilter=0to3&ctcFilter=3to6&ctcFilter=6to10&ctcFilter=10to15&ctcFilter=15to25&ctcFilter=25', 'https://www.naukri.com/devops-jobs-42?ctcFilter=0to3&ctcFilter=3to6&ctcFilter=6to10&ctcFilter=10to15&ctcFilter=15to25&ctcFilter=25', 'https://www.naukri.com/devops-jobs-43?ctcFilter=0to3&ctcFilter=3to6&ctcFilter=6to10&ctcFilter=10to15&ctcFilter=15to25&ctcFilter=25', 'https://www.naukri.com/devops-jobs-44?ctcFilter=0to3&ctcFilter=3to6&ctcFilter=6to10&ctcFilter=10to15&ctcFilter=15to25&ctcFilter=25', 'https://www.naukri.com/devops-jobs-45?ctcFilter=0to3&ctcFilter=3to6&ctcFilter=6to10&ctcFilter=10to15&ctcFilter=15to25&ctcFilter=25', 'https://www.naukri.com/devops-jobs-46?ctcFilter=0to3&ctcFilter=3to6&ctcFilter=6to10&ctcFilter=10to15&ctcFilter=15to25&ctcFilter=25', 'https://www.naukri.com/devops-jobs-5?ctcFilter=0to3&ctcFilter=3to6&ctcFilter=6to10&ctcFilter=10to15&ctcFilter=15to25&ctcFilter=25', 'https://www.naukri.com/devops-jobs-6?ctcFilter=0to3&ctcFilter=3to6&ctcFilter=6to10&ctcFilter=10to15&ctcFilter=15to25&ctcFilter=25', 'https://www.naukri.com/devops-jobs-7?ctcFilter=0to3&ctcFilter=3to6&ctcFilter=6to10&ctcFilter=10to15&ctcFilter=15to25&ctcFilter=25', 'https://www.naukri.com/devops-jobs-8?ctcFilter=0to3&ctcFilter=3to6&ctcFilter=6to10&ctcFilter=10to15&ctcFilter=15to25&ctcFilter=25', 'https://www.naukri.com/devops-jobs-9?ctcFilter=0to3&ctcFilter=3to6&ctcFilter=6to10&ctcFilter=10to15&ctcFilter=15to25&ctcFilter=25']\n"
     ]
    }
   ],
   "source": [
    "# Making the URL list\n",
    "\n",
    "# Page list\n",
    "page_list = list(set(page_list))\n",
    "page_list = sorted(page_list)\n",
    "page_list = [int(digit) for digit in page_list]\n",
    "print(page_list)\n",
    "\n",
    "\n",
    "# base url\n",
    "url = 'https://www.naukri.com/devops-jobs'  # Replace with the URL of the website you want to scrape\n",
    "page_list\n",
    "# # Wait for the results page to load (you might need to adjust the waiting time)\n",
    "time.sleep(2)\n",
    "# print(page_numbers_int)\n",
    "\n",
    "final_url_list_do = []\n",
    "# Example: Extracting information from the results\n",
    "techstack_list =[]\n",
    "for pageid in page_list:\n",
    "    final_url = url +'-'+ str(pageid)+'?ctcFilter=0to3&ctcFilter=3to6&ctcFilter=6to10&ctcFilter=10to15&ctcFilter=15to25&ctcFilter=25'\n",
    "    final_url_list_do.append(final_url)\n",
    "    \n",
    "print(final_url_list_do)\n",
    "\n",
    "driver.quit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "driver = webdriver.Chrome()\n",
    "\n",
    "\n",
    "# base url\n",
    "final_url_list_do\n",
    "\n",
    "# List to store scraped data\n",
    "scraped_data_do = []\n",
    "\n",
    "# Find all job tuple wrapper elements\n",
    "for url in final_url_list_do:\n",
    "    driver.get(url)\n",
    "    wait = WebDriverWait(driver, 10)\n",
    "    job_tuple_wrappers = wait.until(EC.presence_of_all_elements_located((By.CSS_SELECTOR, 'div.srp-jobtuple-wrapper')))\n",
    "    for job_tuple in job_tuple_wrappers:\n",
    "        # Extracting information from each job tuple\n",
    "        job_title = job_tuple.find_element(By.CSS_SELECTOR, 'a.title').text\n",
    "        # company_name = job_tuple.find_element(By.CSS_SELECTOR, 'span.comp-name').text\n",
    "        # rating = job_tuple.find_element(By.CSS_SELECTOR, 'a.rating > span.main-2').text\n",
    "        experience = job_tuple.find_element(By.CSS_SELECTOR, 'span.exp-wrap span.expwdth').get_attribute('title')\n",
    "        salary = job_tuple.find_element(By.CSS_SELECTOR, 'span.ni-job-tuple-icon-srp-rupee span').get_attribute('title')\n",
    "        location = job_tuple.find_element(By.CSS_SELECTOR, 'span.loc-wrap span').get_attribute('title')\n",
    "        job_description = job_tuple.find_element(By.CSS_SELECTOR, 'span.job-desc').text\n",
    "\n",
    "        # Extracting technology stack\n",
    "        tech_stack_elements = job_tuple.find_elements(By.CSS_SELECTOR, 'ul.tags-gt li.tag-li')\n",
    "        tech_stack = [element.text for element in tech_stack_elements]\n",
    "\n",
    "        # Store the scraped data in a dictionary\n",
    "        job_data = {\n",
    "            'job_title': job_title,\n",
    "            # 'company_name': company_name,\n",
    "            # 'rating': rating,\n",
    "            'experience': experience,\n",
    "            'salary': salary,\n",
    "            'location': location,\n",
    "            'job_description': job_description,\n",
    "            'tech_stack': tech_stack,\n",
    "        }\n",
    "\n",
    "        # Append the dictionary to the list\n",
    "        scraped_data_do.append(job_data)\n",
    "\n",
    "driver.quit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Writing to the csv\n",
    "techstack_list_w = scraped_data_do\n",
    "\n",
    "techstack_list_w = pd.DataFrame(techstack_list_w)\n",
    "techstack_list_w.to_csv('JD-Data_DO.csv',index=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***********************\n",
    "Data Scientist URL Creation\n",
    "***********************"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['1', '2', '3', '4', '5', '6', '7', '8', '9', '10', '1', '11', '12', '13', '14', '15', '16', '17', '18', '19', '1', '20', '21', '22', '23', '24', '25', '26', '27', '28', '1', '33', '34', '35', '36', '37', '38', '39']\n"
     ]
    }
   ],
   "source": [
    "\n",
    "driver = webdriver.Chrome()\n",
    "\n",
    "# Open the website\n",
    "url_DataScientist = 'https://www.naukri.com/data-scientist-jobs'  # Replace with the URL of the website you want to scrape\n",
    "driver.get(url_DataScientist)\n",
    "time.sleep(2)\n",
    "page_list_DataScientist = []\n",
    "\n",
    "# Part1\n",
    "result_div_DataScientist = driver.find_element(By.CLASS_NAME, \"styles_pages__v1rAK\")\n",
    "# Find all anchor elements within the div\n",
    "result_elements_DataScientist = result_div_DataScientist.find_elements(By.TAG_NAME, \"a\")\n",
    "# Print the text of each anchor element\n",
    "for element in result_elements_DataScientist:\n",
    "    element =element.text\n",
    "    page_list_DataScientist.append((element))\n",
    "\n",
    "\n",
    "# part2\n",
    "url_DataScientist = 'https://www.naukri.com/data-scientist-jobs-15'  # Replace with the URL of the website you want to scrape\n",
    "driver.get(url_DataScientist)\n",
    "time.sleep(2)\n",
    "result_div_DataScientist = driver.find_element(By.CLASS_NAME, \"styles_pages__v1rAK\")\n",
    "# Find all anchor elements within the div\n",
    "result_elements_DataScientist = result_div_DataScientist.find_elements(By.TAG_NAME, \"a\")\n",
    "# Print the text of each anchor element\n",
    "for element in result_elements_DataScientist:\n",
    "    element =element.text\n",
    "    page_list_DataScientist.append((element))\n",
    "\n",
    "\n",
    "# part3\n",
    "url_DataScientist = 'https://www.naukri.com/data-scientist-jobs-24'  # Replace with the URL of the website you want to scrape\n",
    "driver.get(url_DataScientist)\n",
    "time.sleep(2)\n",
    "result_div_DataScientist = driver.find_element(By.CLASS_NAME, \"styles_pages__v1rAK\")\n",
    "# Find all anchor elements within the div\n",
    "result_elements_DataScientist = result_div_DataScientist.find_elements(By.TAG_NAME, \"a\")\n",
    "# Print the text of each anchor element\n",
    "for element in result_elements_DataScientist:\n",
    "    element =element.text\n",
    "    page_list_DataScientist.append((element))\n",
    "\n",
    "# part4\n",
    "url_DataScientist = 'https://www.naukri.com/data-scientist-jobs-35'  # Replace with the URL of the website you want to scrape\n",
    "driver.get(url_DataScientist)\n",
    "time.sleep(2)\n",
    "result_div_DataScientist = driver.find_element(By.CLASS_NAME, \"styles_pages__v1rAK\")\n",
    "# Find all anchor elements within the div\n",
    "result_elements_DataScientist = result_div_DataScientist.find_elements(By.TAG_NAME, \"a\")\n",
    "# Print the text of each anchor element\n",
    "for element in result_elements_DataScientist:\n",
    "    element =element.text\n",
    "    page_list_DataScientist.append((element))\n",
    "\n",
    "print(page_list_DataScientist)\n",
    "\n",
    "\n",
    "driver.quit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['1', '10', '11', '12', '13', '14', '15', '16', '17', '18', '19', '2', '20', '21', '22', '23', '24', '25', '26', '27', '28', '3', '33', '34', '35', '36', '37', '38', '39', '4', '5', '6', '7', '8', '9']\n",
      "['https://www.naukri.com/data-scientist-jobs-1?roleTypeFilterGid=169&ctcFilter=0to3&ctcFilter=3to6&ctcFilter=6to10&ctcFilter=10to15&ctcFilter=15to25&ctcFilter=25to50&ctcFilter=50to75&clusters=roleGid%2CsalaryRange', 'https://www.naukri.com/data-scientist-jobs-10?roleTypeFilterGid=169&ctcFilter=0to3&ctcFilter=3to6&ctcFilter=6to10&ctcFilter=10to15&ctcFilter=15to25&ctcFilter=25to50&ctcFilter=50to75&clusters=roleGid%2CsalaryRange', 'https://www.naukri.com/data-scientist-jobs-11?roleTypeFilterGid=169&ctcFilter=0to3&ctcFilter=3to6&ctcFilter=6to10&ctcFilter=10to15&ctcFilter=15to25&ctcFilter=25to50&ctcFilter=50to75&clusters=roleGid%2CsalaryRange', 'https://www.naukri.com/data-scientist-jobs-12?roleTypeFilterGid=169&ctcFilter=0to3&ctcFilter=3to6&ctcFilter=6to10&ctcFilter=10to15&ctcFilter=15to25&ctcFilter=25to50&ctcFilter=50to75&clusters=roleGid%2CsalaryRange', 'https://www.naukri.com/data-scientist-jobs-13?roleTypeFilterGid=169&ctcFilter=0to3&ctcFilter=3to6&ctcFilter=6to10&ctcFilter=10to15&ctcFilter=15to25&ctcFilter=25to50&ctcFilter=50to75&clusters=roleGid%2CsalaryRange', 'https://www.naukri.com/data-scientist-jobs-14?roleTypeFilterGid=169&ctcFilter=0to3&ctcFilter=3to6&ctcFilter=6to10&ctcFilter=10to15&ctcFilter=15to25&ctcFilter=25to50&ctcFilter=50to75&clusters=roleGid%2CsalaryRange', 'https://www.naukri.com/data-scientist-jobs-15?roleTypeFilterGid=169&ctcFilter=0to3&ctcFilter=3to6&ctcFilter=6to10&ctcFilter=10to15&ctcFilter=15to25&ctcFilter=25to50&ctcFilter=50to75&clusters=roleGid%2CsalaryRange', 'https://www.naukri.com/data-scientist-jobs-16?roleTypeFilterGid=169&ctcFilter=0to3&ctcFilter=3to6&ctcFilter=6to10&ctcFilter=10to15&ctcFilter=15to25&ctcFilter=25to50&ctcFilter=50to75&clusters=roleGid%2CsalaryRange', 'https://www.naukri.com/data-scientist-jobs-17?roleTypeFilterGid=169&ctcFilter=0to3&ctcFilter=3to6&ctcFilter=6to10&ctcFilter=10to15&ctcFilter=15to25&ctcFilter=25to50&ctcFilter=50to75&clusters=roleGid%2CsalaryRange', 'https://www.naukri.com/data-scientist-jobs-18?roleTypeFilterGid=169&ctcFilter=0to3&ctcFilter=3to6&ctcFilter=6to10&ctcFilter=10to15&ctcFilter=15to25&ctcFilter=25to50&ctcFilter=50to75&clusters=roleGid%2CsalaryRange', 'https://www.naukri.com/data-scientist-jobs-19?roleTypeFilterGid=169&ctcFilter=0to3&ctcFilter=3to6&ctcFilter=6to10&ctcFilter=10to15&ctcFilter=15to25&ctcFilter=25to50&ctcFilter=50to75&clusters=roleGid%2CsalaryRange', 'https://www.naukri.com/data-scientist-jobs-2?roleTypeFilterGid=169&ctcFilter=0to3&ctcFilter=3to6&ctcFilter=6to10&ctcFilter=10to15&ctcFilter=15to25&ctcFilter=25to50&ctcFilter=50to75&clusters=roleGid%2CsalaryRange', 'https://www.naukri.com/data-scientist-jobs-20?roleTypeFilterGid=169&ctcFilter=0to3&ctcFilter=3to6&ctcFilter=6to10&ctcFilter=10to15&ctcFilter=15to25&ctcFilter=25to50&ctcFilter=50to75&clusters=roleGid%2CsalaryRange', 'https://www.naukri.com/data-scientist-jobs-21?roleTypeFilterGid=169&ctcFilter=0to3&ctcFilter=3to6&ctcFilter=6to10&ctcFilter=10to15&ctcFilter=15to25&ctcFilter=25to50&ctcFilter=50to75&clusters=roleGid%2CsalaryRange', 'https://www.naukri.com/data-scientist-jobs-22?roleTypeFilterGid=169&ctcFilter=0to3&ctcFilter=3to6&ctcFilter=6to10&ctcFilter=10to15&ctcFilter=15to25&ctcFilter=25to50&ctcFilter=50to75&clusters=roleGid%2CsalaryRange', 'https://www.naukri.com/data-scientist-jobs-23?roleTypeFilterGid=169&ctcFilter=0to3&ctcFilter=3to6&ctcFilter=6to10&ctcFilter=10to15&ctcFilter=15to25&ctcFilter=25to50&ctcFilter=50to75&clusters=roleGid%2CsalaryRange', 'https://www.naukri.com/data-scientist-jobs-24?roleTypeFilterGid=169&ctcFilter=0to3&ctcFilter=3to6&ctcFilter=6to10&ctcFilter=10to15&ctcFilter=15to25&ctcFilter=25to50&ctcFilter=50to75&clusters=roleGid%2CsalaryRange', 'https://www.naukri.com/data-scientist-jobs-25?roleTypeFilterGid=169&ctcFilter=0to3&ctcFilter=3to6&ctcFilter=6to10&ctcFilter=10to15&ctcFilter=15to25&ctcFilter=25to50&ctcFilter=50to75&clusters=roleGid%2CsalaryRange', 'https://www.naukri.com/data-scientist-jobs-26?roleTypeFilterGid=169&ctcFilter=0to3&ctcFilter=3to6&ctcFilter=6to10&ctcFilter=10to15&ctcFilter=15to25&ctcFilter=25to50&ctcFilter=50to75&clusters=roleGid%2CsalaryRange', 'https://www.naukri.com/data-scientist-jobs-27?roleTypeFilterGid=169&ctcFilter=0to3&ctcFilter=3to6&ctcFilter=6to10&ctcFilter=10to15&ctcFilter=15to25&ctcFilter=25to50&ctcFilter=50to75&clusters=roleGid%2CsalaryRange', 'https://www.naukri.com/data-scientist-jobs-28?roleTypeFilterGid=169&ctcFilter=0to3&ctcFilter=3to6&ctcFilter=6to10&ctcFilter=10to15&ctcFilter=15to25&ctcFilter=25to50&ctcFilter=50to75&clusters=roleGid%2CsalaryRange', 'https://www.naukri.com/data-scientist-jobs-3?roleTypeFilterGid=169&ctcFilter=0to3&ctcFilter=3to6&ctcFilter=6to10&ctcFilter=10to15&ctcFilter=15to25&ctcFilter=25to50&ctcFilter=50to75&clusters=roleGid%2CsalaryRange', 'https://www.naukri.com/data-scientist-jobs-33?roleTypeFilterGid=169&ctcFilter=0to3&ctcFilter=3to6&ctcFilter=6to10&ctcFilter=10to15&ctcFilter=15to25&ctcFilter=25to50&ctcFilter=50to75&clusters=roleGid%2CsalaryRange', 'https://www.naukri.com/data-scientist-jobs-34?roleTypeFilterGid=169&ctcFilter=0to3&ctcFilter=3to6&ctcFilter=6to10&ctcFilter=10to15&ctcFilter=15to25&ctcFilter=25to50&ctcFilter=50to75&clusters=roleGid%2CsalaryRange', 'https://www.naukri.com/data-scientist-jobs-35?roleTypeFilterGid=169&ctcFilter=0to3&ctcFilter=3to6&ctcFilter=6to10&ctcFilter=10to15&ctcFilter=15to25&ctcFilter=25to50&ctcFilter=50to75&clusters=roleGid%2CsalaryRange', 'https://www.naukri.com/data-scientist-jobs-36?roleTypeFilterGid=169&ctcFilter=0to3&ctcFilter=3to6&ctcFilter=6to10&ctcFilter=10to15&ctcFilter=15to25&ctcFilter=25to50&ctcFilter=50to75&clusters=roleGid%2CsalaryRange', 'https://www.naukri.com/data-scientist-jobs-37?roleTypeFilterGid=169&ctcFilter=0to3&ctcFilter=3to6&ctcFilter=6to10&ctcFilter=10to15&ctcFilter=15to25&ctcFilter=25to50&ctcFilter=50to75&clusters=roleGid%2CsalaryRange', 'https://www.naukri.com/data-scientist-jobs-38?roleTypeFilterGid=169&ctcFilter=0to3&ctcFilter=3to6&ctcFilter=6to10&ctcFilter=10to15&ctcFilter=15to25&ctcFilter=25to50&ctcFilter=50to75&clusters=roleGid%2CsalaryRange', 'https://www.naukri.com/data-scientist-jobs-39?roleTypeFilterGid=169&ctcFilter=0to3&ctcFilter=3to6&ctcFilter=6to10&ctcFilter=10to15&ctcFilter=15to25&ctcFilter=25to50&ctcFilter=50to75&clusters=roleGid%2CsalaryRange', 'https://www.naukri.com/data-scientist-jobs-4?roleTypeFilterGid=169&ctcFilter=0to3&ctcFilter=3to6&ctcFilter=6to10&ctcFilter=10to15&ctcFilter=15to25&ctcFilter=25to50&ctcFilter=50to75&clusters=roleGid%2CsalaryRange', 'https://www.naukri.com/data-scientist-jobs-5?roleTypeFilterGid=169&ctcFilter=0to3&ctcFilter=3to6&ctcFilter=6to10&ctcFilter=10to15&ctcFilter=15to25&ctcFilter=25to50&ctcFilter=50to75&clusters=roleGid%2CsalaryRange', 'https://www.naukri.com/data-scientist-jobs-6?roleTypeFilterGid=169&ctcFilter=0to3&ctcFilter=3to6&ctcFilter=6to10&ctcFilter=10to15&ctcFilter=15to25&ctcFilter=25to50&ctcFilter=50to75&clusters=roleGid%2CsalaryRange', 'https://www.naukri.com/data-scientist-jobs-7?roleTypeFilterGid=169&ctcFilter=0to3&ctcFilter=3to6&ctcFilter=6to10&ctcFilter=10to15&ctcFilter=15to25&ctcFilter=25to50&ctcFilter=50to75&clusters=roleGid%2CsalaryRange', 'https://www.naukri.com/data-scientist-jobs-8?roleTypeFilterGid=169&ctcFilter=0to3&ctcFilter=3to6&ctcFilter=6to10&ctcFilter=10to15&ctcFilter=15to25&ctcFilter=25to50&ctcFilter=50to75&clusters=roleGid%2CsalaryRange', 'https://www.naukri.com/data-scientist-jobs-9?roleTypeFilterGid=169&ctcFilter=0to3&ctcFilter=3to6&ctcFilter=6to10&ctcFilter=10to15&ctcFilter=15to25&ctcFilter=25to50&ctcFilter=50to75&clusters=roleGid%2CsalaryRange']\n"
     ]
    }
   ],
   "source": [
    "# Making the URL list\n",
    "\n",
    "# Page list\n",
    "page_list_DataScientist = list(set(page_list_DataScientist))\n",
    "page_list_DataScientist = sorted(page_list_DataScientist)\n",
    "page_list_DataScientist_int = [int(digit) for digit in page_list_DataScientist]\n",
    "print(page_list_DataScientist)\n",
    "\n",
    "\n",
    "# base url\n",
    "url = 'https://www.naukri.com/data-scientist-jobs'  # Replace with the URL of the website you want to scrape\n",
    "page_list_DataScientist\n",
    "# # Wait for the results page to load (you might need to adjust the waiting time)\n",
    "time.sleep(2)\n",
    "# print(page_numbers_int)\n",
    "\n",
    "final_url_list_DataScientist = []\n",
    "# Example: Extracting information from the results\n",
    "techstack_list =[]\n",
    "for pageid in page_list_DataScientist:\n",
    "    final_url_DataScientist = url +'-'+ str(pageid)+'?roleTypeFilterGid=169&ctcFilter=0to3&ctcFilter=3to6&ctcFilter=6to10&ctcFilter=10to15&ctcFilter=15to25&ctcFilter=25to50&ctcFilter=50to75&clusters=roleGid%2CsalaryRange'\n",
    "    final_url_list_DataScientist.append(final_url_DataScientist)\n",
    "    \n",
    "print(final_url_list_DataScientist)\n",
    "\n",
    "driver.quit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "NoSuchElementException",
     "evalue": "Message: no such element: Unable to locate element: {\"method\":\"css selector\",\"selector\":\"span.ni-job-tuple-icon-srp-rupee span\"}\n  (Session info: chrome=119.0.6045.199); For documentation on this error, please visit: https://www.selenium.dev/documentation/webdriver/troubleshooting/errors#no-such-element-exception\nStacktrace:\n0   chromedriver                        0x0000000104d9e004 chromedriver + 4169732\n1   chromedriver                        0x0000000104d95ff8 chromedriver + 4136952\n2   chromedriver                        0x00000001049eb500 chromedriver + 292096\n3   chromedriver                        0x0000000104a307a0 chromedriver + 575392\n4   chromedriver                        0x0000000104a25db4 chromedriver + 531892\n5   chromedriver                        0x0000000104a6b818 chromedriver + 817176\n6   chromedriver                        0x0000000104a245e8 chromedriver + 525800\n7   chromedriver                        0x0000000104a254b8 chromedriver + 529592\n8   chromedriver                        0x0000000104d64334 chromedriver + 3932980\n9   chromedriver                        0x0000000104d68970 chromedriver + 3950960\n10  chromedriver                        0x0000000104d4c774 chromedriver + 3835764\n11  chromedriver                        0x0000000104d69478 chromedriver + 3953784\n12  chromedriver                        0x0000000104d3eab4 chromedriver + 3779252\n13  chromedriver                        0x0000000104d85914 chromedriver + 4069652\n14  chromedriver                        0x0000000104d85a90 chromedriver + 4070032\n15  chromedriver                        0x0000000104d95c70 chromedriver + 4136048\n16  libsystem_pthread.dylib             0x000000018b285034 _pthread_start + 136\n17  libsystem_pthread.dylib             0x000000018b27fe3c thread_start + 8\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNoSuchElementException\u001b[0m                    Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[6], line 21\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[38;5;66;03m# company_name = job_tuple.find_element(By.CSS_SELECTOR, 'span.comp-name').text\u001b[39;00m\n\u001b[1;32m     19\u001b[0m \u001b[38;5;66;03m# rating = job_tuple.find_element(By.CSS_SELECTOR, 'a.rating > span.main-2').text\u001b[39;00m\n\u001b[1;32m     20\u001b[0m experience \u001b[38;5;241m=\u001b[39m job_tuple\u001b[38;5;241m.\u001b[39mfind_element(By\u001b[38;5;241m.\u001b[39mCSS_SELECTOR, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mspan.exp-wrap span.expwdth\u001b[39m\u001b[38;5;124m'\u001b[39m)\u001b[38;5;241m.\u001b[39mget_attribute(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtitle\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m---> 21\u001b[0m salary \u001b[38;5;241m=\u001b[39m \u001b[43mjob_tuple\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfind_element\u001b[49m\u001b[43m(\u001b[49m\u001b[43mBy\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mCSS_SELECTOR\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mspan.ni-job-tuple-icon-srp-rupee span\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mget_attribute(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtitle\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m     22\u001b[0m location \u001b[38;5;241m=\u001b[39m job_tuple\u001b[38;5;241m.\u001b[39mfind_element(By\u001b[38;5;241m.\u001b[39mCSS_SELECTOR, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mspan.loc-wrap span\u001b[39m\u001b[38;5;124m'\u001b[39m)\u001b[38;5;241m.\u001b[39mget_attribute(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtitle\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m     23\u001b[0m job_description \u001b[38;5;241m=\u001b[39m job_tuple\u001b[38;5;241m.\u001b[39mfind_element(By\u001b[38;5;241m.\u001b[39mCSS_SELECTOR, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mspan.job-desc\u001b[39m\u001b[38;5;124m'\u001b[39m)\u001b[38;5;241m.\u001b[39mtext\n",
      "File \u001b[0;32m~/anaconda3/envs/isb_core_ml/lib/python3.9/site-packages/selenium/webdriver/remote/webelement.py:416\u001b[0m, in \u001b[0;36mWebElement.find_element\u001b[0;34m(self, by, value)\u001b[0m\n\u001b[1;32m    413\u001b[0m     by \u001b[38;5;241m=\u001b[39m By\u001b[38;5;241m.\u001b[39mCSS_SELECTOR\n\u001b[1;32m    414\u001b[0m     value \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m[name=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mvalue\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m]\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m--> 416\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_execute\u001b[49m\u001b[43m(\u001b[49m\u001b[43mCommand\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mFIND_CHILD_ELEMENT\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m{\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43musing\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mby\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mvalue\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m}\u001b[49m\u001b[43m)\u001b[49m[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mvalue\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n",
      "File \u001b[0;32m~/anaconda3/envs/isb_core_ml/lib/python3.9/site-packages/selenium/webdriver/remote/webelement.py:394\u001b[0m, in \u001b[0;36mWebElement._execute\u001b[0;34m(self, command, params)\u001b[0m\n\u001b[1;32m    392\u001b[0m     params \u001b[38;5;241m=\u001b[39m {}\n\u001b[1;32m    393\u001b[0m params[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mid\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_id\n\u001b[0;32m--> 394\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_parent\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexecute\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcommand\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparams\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/isb_core_ml/lib/python3.9/site-packages/selenium/webdriver/remote/webdriver.py:347\u001b[0m, in \u001b[0;36mWebDriver.execute\u001b[0;34m(self, driver_command, params)\u001b[0m\n\u001b[1;32m    345\u001b[0m response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcommand_executor\u001b[38;5;241m.\u001b[39mexecute(driver_command, params)\n\u001b[1;32m    346\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m response:\n\u001b[0;32m--> 347\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43merror_handler\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcheck_response\u001b[49m\u001b[43m(\u001b[49m\u001b[43mresponse\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    348\u001b[0m     response[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mvalue\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_unwrap_value(response\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mvalue\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m))\n\u001b[1;32m    349\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m response\n",
      "File \u001b[0;32m~/anaconda3/envs/isb_core_ml/lib/python3.9/site-packages/selenium/webdriver/remote/errorhandler.py:229\u001b[0m, in \u001b[0;36mErrorHandler.check_response\u001b[0;34m(self, response)\u001b[0m\n\u001b[1;32m    227\u001b[0m         alert_text \u001b[38;5;241m=\u001b[39m value[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124malert\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtext\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    228\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m exception_class(message, screen, stacktrace, alert_text)  \u001b[38;5;66;03m# type: ignore[call-arg]  # mypy is not smart enough here\u001b[39;00m\n\u001b[0;32m--> 229\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m exception_class(message, screen, stacktrace)\n",
      "\u001b[0;31mNoSuchElementException\u001b[0m: Message: no such element: Unable to locate element: {\"method\":\"css selector\",\"selector\":\"span.ni-job-tuple-icon-srp-rupee span\"}\n  (Session info: chrome=119.0.6045.199); For documentation on this error, please visit: https://www.selenium.dev/documentation/webdriver/troubleshooting/errors#no-such-element-exception\nStacktrace:\n0   chromedriver                        0x0000000104d9e004 chromedriver + 4169732\n1   chromedriver                        0x0000000104d95ff8 chromedriver + 4136952\n2   chromedriver                        0x00000001049eb500 chromedriver + 292096\n3   chromedriver                        0x0000000104a307a0 chromedriver + 575392\n4   chromedriver                        0x0000000104a25db4 chromedriver + 531892\n5   chromedriver                        0x0000000104a6b818 chromedriver + 817176\n6   chromedriver                        0x0000000104a245e8 chromedriver + 525800\n7   chromedriver                        0x0000000104a254b8 chromedriver + 529592\n8   chromedriver                        0x0000000104d64334 chromedriver + 3932980\n9   chromedriver                        0x0000000104d68970 chromedriver + 3950960\n10  chromedriver                        0x0000000104d4c774 chromedriver + 3835764\n11  chromedriver                        0x0000000104d69478 chromedriver + 3953784\n12  chromedriver                        0x0000000104d3eab4 chromedriver + 3779252\n13  chromedriver                        0x0000000104d85914 chromedriver + 4069652\n14  chromedriver                        0x0000000104d85a90 chromedriver + 4070032\n15  chromedriver                        0x0000000104d95c70 chromedriver + 4136048\n16  libsystem_pthread.dylib             0x000000018b285034 _pthread_start + 136\n17  libsystem_pthread.dylib             0x000000018b27fe3c thread_start + 8\n"
     ]
    }
   ],
   "source": [
    "driver = webdriver.Chrome()\n",
    "\n",
    "\n",
    "# base url\n",
    "final_url_list_DataScientist\n",
    "\n",
    "# List to store scraped data\n",
    "scraped_data_ds = []\n",
    "\n",
    "# Find all job tuple wrapper elements\n",
    "for url in final_url_list_DataScientist:\n",
    "    driver.get(url)\n",
    "    wait = WebDriverWait(driver, 10)\n",
    "    job_tuple_wrappers = wait.until(EC.presence_of_all_elements_located((By.CSS_SELECTOR, 'div.srp-jobtuple-wrapper')))\n",
    "    for job_tuple in job_tuple_wrappers:\n",
    "        # Extracting information from each job tuple\n",
    "        job_title = job_tuple.find_element(By.CSS_SELECTOR, 'a.title').text\n",
    "        # company_name = job_tuple.find_element(By.CSS_SELECTOR, 'span.comp-name').text\n",
    "        # rating = job_tuple.find_element(By.CSS_SELECTOR, 'a.rating > span.main-2').text\n",
    "        experience = job_tuple.find_element(By.CSS_SELECTOR, 'span.exp-wrap span.expwdth').get_attribute('title')\n",
    "        salary = job_tuple.find_element(By.CSS_SELECTOR, 'span.ni-job-tuple-icon-srp-rupee span').get_attribute('title')\n",
    "        location = job_tuple.find_element(By.CSS_SELECTOR, 'span.loc-wrap span').get_attribute('title')\n",
    "        job_description = job_tuple.find_element(By.CSS_SELECTOR, 'span.job-desc').text\n",
    "\n",
    "        # Extracting technology stack\n",
    "        tech_stack_elements = job_tuple.find_elements(By.CSS_SELECTOR, 'ul.tags-gt li.tag-li')\n",
    "        tech_stack = [element.text for element in tech_stack_elements]\n",
    "\n",
    "        # Store the scraped data in a dictionary\n",
    "        job_data = {\n",
    "            'job_title': job_title,\n",
    "            # 'company_name': company_name,\n",
    "            # 'rating': rating,\n",
    "            'experience': experience,\n",
    "            'salary': salary,\n",
    "            'location': location,\n",
    "            'job_description': job_description,\n",
    "            'tech_stack': tech_stack,\n",
    "        }\n",
    "\n",
    "        # Append the dictionary to the list\n",
    "        scraped_data_ds.append(job_data)\n",
    "\n",
    "driver.quit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Writing to the csv\n",
    "techstack_list_w = scraped_data_ds\n",
    "\n",
    "techstack_list_w = pd.DataFrame(techstack_list_w)\n",
    "techstack_list_w.to_csv('JD-Data_DS.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
